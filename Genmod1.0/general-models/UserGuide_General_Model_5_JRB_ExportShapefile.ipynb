{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Export a shapefile of a general MODFLOW model from the NHDPlus dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a grid-search approach to finding hydraulic conductivities that result in heads that seem reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project specific variables are imported in the model_spec.py and gen_mod_dict.py files that must be included in the notebook directory. The first first includes pathnames to data sources that will be different for each user. The second file includes a dictionary of model-specific information such as  cell size, default hydraulic parameter values, and scenario defintion (e.g. include bedrock, number of layers, etc.). There are examples in the repository. Run the following cells up to the \"Run to here\" cell to get a pull-down menu of models in the model_dict. Then, without re-running that cell, run all the remaining cells.  Re-running the following cell would re-set the model to the first one in the list, which you probably don't want. If you use the notebook option to run all cells below, it runs the cell you're in, so if you use that option, move to the next cell (below the pull-down menu of models) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "from model_specs import *\n",
    "from gen_mod_dict import *\n",
    "\n",
    "import os, sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import gdal\n",
    "gdal.UseExceptions()\n",
    "\n",
    "from flopy.utils.postprocessing import get_water_table\n",
    "\n",
    "\n",
    "import flopy.utils.binaryfile as bf\n",
    "from matplotlib import colors\n",
    "import flopy as fp\n",
    "import pandas as pd\n",
    "# import ipyparallel as ipp\n",
    "# from model_specs import *\n",
    "# from gen_mod_dict import *\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is a template for making this notebook into a batch script. To do so, save this notebook as a .py file and edit it as follows. Comment out all the notebook-specific commands (drop-down menu stuff and commands preceded by %). Indent everything below the next cell twice so that it falls within the 'for' loop and the 'try' statement. Move the 'except' statement to the end of the script. Comment out lines in the cell after 'Preliminary stuff' so that the model is selected in the 'for' loop from gen_mod_dict. You can leave the print statement in that cell uncommented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying Niantic250\n",
      "trying CoastalCT250\n",
      "trying CoastalCT500\n",
      "trying Neversink\n",
      "trying Niantic500\n",
      "trying CoastalCT\n",
      "trying Assabet\n",
      "trying Niantic\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_dict.items():   # from \"gen_mod_dict.py\"\n",
    "    md = key\n",
    "    ms = model_dict[md]\n",
    "    print('trying {}'.format(md))\n",
    "    try:\n",
    "        pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = list(model_dict.keys())\n",
    "models.sort()\n",
    "model_area = Dropdown(\n",
    "    options=models,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to here to initiate notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First time using this notebook in this session (before restarting the notebook), run the cells up to this point. Then select your model from the dropdown list above. Move your cursor to this cell and use the toolbar menu Cell --> Run All Below.  After the first time, if you want to run another model, select your model and start running from this cell--you don't need to re-run the cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model being processed is CoastalCT500\n",
      "\n",
      "The resolution is 152.40 m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = model_area.value\n",
    "ms = model_dict[md]\n",
    "print('The model being processed is {}\\n'.format(md))\n",
    "\n",
    "\n",
    "if 'L' in ms.keys():\n",
    "    L = ms['L']\n",
    "print('The resolution is %0.2f m\\n'%(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the calibration scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy model to be calibrated (parent model) to new directory. Define the weight, which is used after all the models are run to find the best set of parameters by weighting the error rates. It is specified here so it can be used in the directory name. Weights > 1 result in fewer dry drains and more cells with heads above land surface. That tends to mean lower hydraulic conductivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hydro_wt = 1.0\n",
    "calib=False\n",
    "PEST=False\n",
    "label = \"DRN0_smoothDrn_GHBCorrections_PEST - Copy\"\n",
    "label=\"DRN0_PEST__WellDateAdjust_RIV\"\n",
    "label=\"DRN0_PEST\"\n",
    "label=\"SFR_DRN0_PEST\"\n",
    "# label=\"DRN0\"\n",
    "# label=\"DRN_cal_wt_1.00\"\n",
    "\n",
    "geo_ws = os.path.join(proj_dir, ms['ws'])\n",
    "parent_ws = os.path.join(geo_ws, scenario_dir)\n",
    "if calib:\n",
    "    dir_name = '{}_cal_wt_{:4.2f}'.format(scenario_dir, hydro_wt)\n",
    "else:\n",
    "    dir_name = scenario_dir\n",
    "    \n",
    "if PEST:\n",
    "    dir_name = dir_name + \"_PEST\"\n",
    "    \n",
    "if label!='':\n",
    "    dir_name = dir_name +\"_\"+str(label)\n",
    "    \n",
    "model_ws = os.path.join(geo_ws, dir_name)\n",
    "\n",
    "if not os.path.exists(model_ws):\n",
    "    print('This calibration scenario has not been completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_raster(dst_file, data, NCOL, NROW, gt, proj, nodata):\n",
    "    '''\n",
    "    Writes numpy array to a GeoTiff file.\n",
    "    \n",
    "    dst_file : name of file to write\n",
    "    data : 2D numpy array\n",
    "    NCOL, NROW : number of rows and columns. These may coincide with a MODFLOW grid.\n",
    "    gt : 6-element geotransform list [C, A, B, F, E, D]. Gives the coordinates of one pixel\n",
    "        (the upper left pixel). If there is no rotation, B=D=0. If cells are square, A=-E.   \n",
    "        Letter designations come from the original documentation.\n",
    "        \n",
    "        C = x coordinate in map units of the upper left corner of the upper left pixel\n",
    "        A = distance from C along x axis to upper right pixel corner of the upper left pixel\n",
    "        B = distance from C along x axis to lower left pixel corner of the upper left pixel,\n",
    "        F = y coordinate in map units of the upper left corner of the upper left pixel\n",
    "        E = distance from C along y axis to lower left pixel corner of the upper left pixel\n",
    "        D = distance from C along y axis to upper right pixel corner of the upper left pixel\n",
    "        \n",
    "    proj : projection of the GeoTiff\n",
    "    nodata : value to use as missing data in the GeoTiff\n",
    "    '''\n",
    "    import gdal\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst = driver.Create(dst_file, NCOL, NROW, 1, gdal.GDT_Float32)\n",
    "    dst.SetGeoTransform(gt)\n",
    "    dst.SetProjection(proj)\n",
    "    band = dst.GetRasterBand(1)\n",
    "    band.SetNoDataValue(nodata)\n",
    "    band.WriteArray(data)\n",
    "    dst = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing model and some packages needed for parameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nam_file = '{}.nam'.format(md)\n",
    "mf = fp.modflow.Modflow.load(os.path.join(model_ws,nam_file), version='mfnwt', exe_name=mfpth, verbose=False, model_ws=model_ws, load_only=None)\n",
    "\n",
    "bas = mf.get_package('BAS6')\n",
    "dis = mf.get_package('DIS')\n",
    "upw = mf.get_package('UPW')\n",
    "oc = mf.get_package('OC')\n",
    "well = mf.get_package('WEL')\n",
    "rch = mf.get_package('RCH')\n",
    "head_file_pth = os.path.join(model_ws, '{}.hds'.format(md))\n",
    "\n",
    "ibound = bas.ibound\n",
    "botm = dis.getbotm()\n",
    "hdsobj = bf.HeadFile(head_file_pth)\n",
    "hds = hdsobj.get_data()\n",
    "wt = get_water_table(heads=hds, nodata=-8890)\n",
    "\n",
    "model_file = os.path.join(geo_ws, dir_name,'model_grid.csv')\n",
    "model_grid = pd.read_csv(model_file, na_values=[hnoflo, hdry])\n",
    "\n",
    "land_surface = model_grid.top\n",
    "top = land_surface.values.reshape(dis.nrow, dis.ncol)\n",
    "node = model_grid.node_num.values.reshape(dis.nrow,dis.ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert obs type to numeric values\n",
    "model_grid['obs_type_int'] = 0\n",
    "model_grid.loc[model_grid.obs_type==\"hydro\",'obs_type_int']=1\n",
    "model_grid.loc[model_grid.obs_type==\"topo\",\"obs_type_int\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a dictionary of heads to export with the model parameters\n",
    "other_dict={}\n",
    "\n",
    "#loop through the model layers\n",
    "for i in range(hds.shape[0]):\n",
    "    other_dict[\"head_\"+str(i)]=hds[i,:,:]\n",
    "\n",
    "    zone_file = os.path.join(model_ws,'zone_array_detailed.npz')    \n",
    "if not os.path.isfile(zone_file):\n",
    "    zone_file = os.path.join(model_ws, 'zone_array.npz')\n",
    "    \n",
    "if os.path.isfile(zone_file):\n",
    "    zones = np.load(zone_file)\n",
    "    zones = zones['zone']\n",
    "    for i in range(zones.shape[0]):\n",
    "        other_dict[\"surfzone_\"+str(i)]=zones[i,:,:]\n",
    "\n",
    "other_dict[\"ZoneBud\"]=model_grid.HUC12_shortCD.values.reshape(dis.nrow, dis.ncol)\n",
    "try:\n",
    "    other_dict[\"Septic_flux\"]=model_grid.Septic_flux.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"sep_cm_yr\"]=other_dict[\"Septic_flux\"]/L/L*365*100  #converts m3/d to cm/yr\n",
    "    model_grid['PrivWell_flux']=model_grid.population.values*np.abs(model_grid.pws.values-1)*useResPerCap\n",
    "    model_grid['NetPrivSeptLoss'] = model_grid.population.values*np.abs(model_grid.pws.values-1)*useResPerCap-model_grid.Septic_flux.values\n",
    "    other_dict['PrivWell_flux']=model_grid.population.values.reshape(dis.nrow, dis.ncol)*np.abs(model_grid.pws.values.reshape(dis.nrow, dis.ncol)-1)*useResPerCap\n",
    "    other_dict['PriWe_cm_yr']=other_dict['PrivWell_flux']/L/L*365*100  #converts m3/d to cm/yr\n",
    "    model_grid['NetPrivSeptLoss'] = model_grid.population.values*np.abs(model_grid.pws.values-1)*useResPerCap-model_grid.Septic_flux.values\n",
    "    other_dict['NetPrivSeptLoss']= model_grid.NetPrivSeptLoss.values.reshape(dis.nrow,dis.ncol)\n",
    "    other_dict['NetSepLoss_cm_yr']=other_dict['NetPrivSeptLoss']/L/L*365*100  #converts m3/d to cm/yr\n",
    "    other_dict[\"Pop\"]=model_grid.population.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"Coast_Deep\"]=model_grid.Coast_Deep.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"Coast_Shallow\"]=model_grid.Coast_Shallow.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"ghb_sea\"]=model_grid.ghb_sea.values.reshape(dis.nrow, dis.ncol)\n",
    "except:\n",
    "    pass\n",
    "other_dict[\"arbolateSu\"]=model_grid.arbolateSu.values.reshape(dis.nrow, dis.ncol)\n",
    "try:\n",
    "    other_dict[\"SurfGeo\"]=model_grid.SurfGeo.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"BedLithSimp\"]=model_grid.BedLithSimp.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"PerWater\"]=model_grid.PerWater.values.reshape(dis.nrow, dis.ncol)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "other_dict[\"ObsType\"]=model_grid.obs_type_int.values.reshape(dis.nrow, dis.ncol)\n",
    "other_dict[\"WetlandPer\"]=model_grid.WetlandPer.values.reshape(dis.nrow, dis.ncol)\n",
    "other_dict[\"reachcode\"]=model_grid.reachcode.values.reshape(dis.nrow,dis.ncol)\n",
    "other_dict[\"nlcd\"]=model_grid.nlcd.values.reshape(dis.nrow, dis.ncol)\n",
    "other_dict[\"obs_type\"]=np.array([1 if x==\"hydro\"else 2 if x==\"topo\" else 0 for x in model_grid.obs_type.values]).reshape(dis.nrow, dis.ncol)\n",
    "try:\n",
    "    other_dict[\"HUC12_shortCD\"]=model_grid.HUC12_shortCD.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"baseflowGage\"]=model_grid.baseflowGage.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict[\"HUC12_shortCD_ext\"]=model_grid.HUC12_shortCD_ext.values.reshape(dis.nrow, dis.ncol)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    other_dict[\"Coast_major\"]=model_grid.Coast_major.values.reshape(dis.nrow, dis.ncol)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    other_dict[\"Pop_raw\"]=model_grid.population_float.values.reshape(dis.nrow, dis.ncol)\n",
    "except:\n",
    "    pass\n",
    "# other_dict[\"PerWater\"]=model_grid.PerWater.values.reshape(dis.nrow, dis.ncol)\n",
    "other_dict[\"wt\"]=wt\n",
    "model_grid['wt'] = wt.ravel() \n",
    "other_dict[\"DTW_m\"]=top - wt\n",
    "other_dict[\"land_surface\"]=top\n",
    "other_dict[\"node\"]=node\n",
    "try:\n",
    "    other_dict[\"Rech_noSep\"]=rch.rech.array[0][0]-other_dict[\"Septic_flux\"]/L/L\n",
    "    other_dict['Rech_nat_cm_yr']=other_dict[\"Rech_noSep\"]*100*365\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.08102106   0.13796157   0.21572173   0.39339516  37.74043213]\n",
      "[ -6.13814540e+01  -1.57244831e+00  -1.04545610e+00  -6.89982050e-01\n",
      "  -1.91558939e-02]\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(model_grid.NetPrivSeptLoss[(model_grid.ibound==1)&(model_grid.NetPrivSeptLoss>0)],[0,25,50,75,100]))\n",
    "print(np.percentile(model_grid.NetPrivSeptLoss[(model_grid.ibound==1)&(model_grid.NetPrivSeptLoss<0)],[0,25,50,75,100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_num', 'node_num.1', 'node_num.1.1', 'ibound', 'SHEDS',\n",
       "       'arbolateSu', 'gess_poly', 'lake', 'kauffman_CTquat_thk',\n",
       "       'HUC12_shortCD', 'HUC12_shortCD_ext', 'sewer', 'pws', 'well_PWSFlux',\n",
       "       'well_Glacial', 'BedLithSimp', 'SurfGeo', 'embayment', 'baseflowGage',\n",
       "       'ned', 'ned_mean', 'kauffman_bedrock_el', 'slope', 'ned_coast_min',\n",
       "       'catchment', 'soller_thk', 'soller_bedrock_el', 'nlcd', 'clear',\n",
       "       'clear_per_grass', 'nlcd_ag', 'WetlandPer', 'PerDev', 'PerImp',\n",
       "       'population', 'rch_eff_m_SWB_NAWQA', 'rch_eff_m_Reitz_2013',\n",
       "       'rch_m_Wolock', 'Coast_Deep', 'Coast_Shallow', 'PerWater', 'PerSand',\n",
       "       'PerClay', 'PerSilt', 'NDep_dry', 'NDep_wet', 'edge', 'ghb', 'stage',\n",
       "       'segment_len', 'order', 'arbolateSum', 'reachcode', 'reach_intermit',\n",
       "       'reach_len', 'reach_int', 'riv_coast', 'road', 'road_length', 'ghb_sea',\n",
       "       'fresh_head', 'Coast_all', 'Coast_major', 'top', 'lay', 'row', 'col',\n",
       "       'obs_type', 'xc', 'yc', 'population_float', 'K0', 'K0_noLakes',\n",
       "       'drain_elev', 'Septic_flux', 'PrivateWell_flux', 'recharge',\n",
       "       'pre_cal_heads', 'pre_cal_K', 'thk', 'thkR', 'obs_type_int',\n",
       "       'PrivWell_flux', 'NetPrivSeptLoss', 'wt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_float</th>\n",
       "      <th>population</th>\n",
       "      <th>pws</th>\n",
       "      <th>sewer</th>\n",
       "      <th>NetPrivSeptLoss</th>\n",
       "      <th>Septic_flux</th>\n",
       "      <th>PrivWell_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>649056</th>\n",
       "      <td>136.898987</td>\n",
       "      <td>136.898987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.641818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.641818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650547</th>\n",
       "      <td>115.917328</td>\n",
       "      <td>115.917328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.865119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.865119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713152</th>\n",
       "      <td>114.050552</td>\n",
       "      <td>114.050552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.529099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.529099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740020</th>\n",
       "      <td>142.206085</td>\n",
       "      <td>142.206085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.597095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.597095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741511</th>\n",
       "      <td>148.715134</td>\n",
       "      <td>148.715134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.768724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.768724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744497</th>\n",
       "      <td>146.926743</td>\n",
       "      <td>146.926743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.446814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.446814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745988</th>\n",
       "      <td>162.023560</td>\n",
       "      <td>162.023560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.164241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.164241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760837</th>\n",
       "      <td>206.675262</td>\n",
       "      <td>206.675262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.201547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.201547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762327</th>\n",
       "      <td>206.675262</td>\n",
       "      <td>209.669067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.740432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.740432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762328</th>\n",
       "      <td>155.006439</td>\n",
       "      <td>155.006439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.901159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.901159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771297</th>\n",
       "      <td>152.640305</td>\n",
       "      <td>152.640305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.475255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.475255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843812</th>\n",
       "      <td>252.859863</td>\n",
       "      <td>255.903610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-36.706174</td>\n",
       "      <td>36.706174</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845302</th>\n",
       "      <td>137.778091</td>\n",
       "      <td>137.778091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.080048</td>\n",
       "      <td>21.080048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845303</th>\n",
       "      <td>227.072205</td>\n",
       "      <td>227.072205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.742047</td>\n",
       "      <td>34.742047</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845304</th>\n",
       "      <td>166.691956</td>\n",
       "      <td>166.691956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.503869</td>\n",
       "      <td>25.503869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846793</th>\n",
       "      <td>267.457306</td>\n",
       "      <td>269.306671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-36.053431</td>\n",
       "      <td>36.053431</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846794</th>\n",
       "      <td>251.704376</td>\n",
       "      <td>251.704376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.510770</td>\n",
       "      <td>38.510770</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848284</th>\n",
       "      <td>401.185974</td>\n",
       "      <td>401.185974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-61.381454</td>\n",
       "      <td>61.381454</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848285</th>\n",
       "      <td>172.405502</td>\n",
       "      <td>172.405502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.378042</td>\n",
       "      <td>26.378042</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849774</th>\n",
       "      <td>320.948761</td>\n",
       "      <td>323.773621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-41.281136</td>\n",
       "      <td>41.281136</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849775</th>\n",
       "      <td>353.660065</td>\n",
       "      <td>353.660065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-54.109990</td>\n",
       "      <td>54.109990</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        population_float  population  pws  sewer  NetPrivSeptLoss  \\\n",
       "649056        136.898987  136.898987  0.0    1.0        24.641818   \n",
       "650547        115.917328  115.917328  0.0    1.0        20.865119   \n",
       "713152        114.050552  114.050552  0.0    1.0        20.529099   \n",
       "740020        142.206085  142.206085  0.0    1.0        25.597095   \n",
       "741511        148.715134  148.715134  0.0    1.0        26.768724   \n",
       "744497        146.926743  146.926743  0.0    1.0        26.446814   \n",
       "745988        162.023560  162.023560  0.0    1.0        29.164241   \n",
       "760837        206.675262  206.675262  0.0    1.0        37.201547   \n",
       "762327        206.675262  209.669067  0.0    1.0        37.740432   \n",
       "762328        155.006439  155.006439  0.0    1.0        27.901159   \n",
       "771297        152.640305  152.640305  0.0    1.0        27.475255   \n",
       "843812        252.859863  255.903610  1.0    0.0       -36.706174   \n",
       "845302        137.778091  137.778091  1.0    0.0       -21.080048   \n",
       "845303        227.072205  227.072205  1.0    0.0       -34.742047   \n",
       "845304        166.691956  166.691956  1.0    0.0       -25.503869   \n",
       "846793        267.457306  269.306671  1.0    0.0       -36.053431   \n",
       "846794        251.704376  251.704376  1.0    0.0       -38.510770   \n",
       "848284        401.185974  401.185974  1.0    0.0       -61.381454   \n",
       "848285        172.405502  172.405502  1.0    0.0       -26.378042   \n",
       "849774        320.948761  323.773621  1.0    0.0       -41.281136   \n",
       "849775        353.660065  353.660065  1.0    0.0       -54.109990   \n",
       "\n",
       "        Septic_flux  PrivWell_flux  \n",
       "649056     0.000000      24.641818  \n",
       "650547     0.000000      20.865119  \n",
       "713152     0.000000      20.529099  \n",
       "740020     0.000000      25.597095  \n",
       "741511     0.000000      26.768724  \n",
       "744497     0.000000      26.446814  \n",
       "745988     0.000000      29.164241  \n",
       "760837     0.000000      37.201547  \n",
       "762327     0.000000      37.740432  \n",
       "762328     0.000000      27.901159  \n",
       "771297     0.000000      27.475255  \n",
       "843812    36.706174       0.000000  \n",
       "845302    21.080048       0.000000  \n",
       "845303    34.742047       0.000000  \n",
       "845304    25.503869       0.000000  \n",
       "846793    36.053431       0.000000  \n",
       "846794    38.510770       0.000000  \n",
       "848284    61.381454       0.000000  \n",
       "848285    26.378042       0.000000  \n",
       "849774    41.281136       0.000000  \n",
       "849775    54.109990       0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.loc[(np.abs(model_grid.NetPrivSeptLoss)>20)&(model_grid.ibound==1),[\"population_float\",\"population\",\"pws\",\"sewer\",\"NetPrivSeptLoss\",\"Septic_flux\",\"PrivWell_flux\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in the model grid with travel times, if it exits\n",
    "if os.path.isfile(model_file.replace(\"model_grid\",\"model_grid2\")):\n",
    "    model_grid2 = pd.read_csv(model_file.replace(\"model_grid\",\"model_grid2\"), na_values=[hnoflo, hdry])\n",
    "    other_dict['travTimeYrsDis']=model_grid2.medTimeOut_yrs.values.reshape(dis.nrow,dis.ncol)\n",
    "    other_dict['travTimeYrsRe']=model_grid2.medTimeIn_yrs.values.reshape(dis.nrow,dis.ncol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Extract an array of reduced pumping wells (if applicable) and extremely thin cells (that were turned inactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check if any wells had reduced pumping\n",
    "listFile = os.path.join(model_ws,\"%s.list\"%md)\n",
    "o_file = open(listFile)\n",
    "reducedPumping = False\n",
    "wellList = False\n",
    "colList = \"\"\n",
    "wellDFList = []\n",
    "thinList = []\n",
    "for line in o_file:\n",
    "    if \"WELLS WITH REDUCED PUMPING FOR STRESS PERIOD\" in line:\n",
    "        reducedPumping = True\n",
    "        wellList = True\n",
    "        continue\n",
    "    #this gets the end of the list of wells\n",
    "    if reducedPumping and len(line[:-1].strip())==0 and wellList:\n",
    "        wellList = False\n",
    "    if reducedPumping and wellList:\n",
    "        if colList ==\"\":\n",
    "            colList = line[:-1].strip().split()\n",
    "            colList = [x.replace(\".\",\"\") for x in colList]\n",
    "            colList = [x.replace(\"-\",\"\") for x in colList]\n",
    "        else:\n",
    "            wellDFList.append(line[:-1].strip().split())\n",
    "    if len(line[:-1].strip())>0:\n",
    "        if line[:-1].strip().split()[0]==\"Extremely\":\n",
    "            thinCol = line[:-1].strip().split()[6]\n",
    "            thinRow = line[:-1].strip().split()[10]\n",
    "            thinList.append([int(thinRow)-1, int(thinCol)-1])\n",
    "            \n",
    "o_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if reducedPumping:\n",
    "    wellDF = pd.DataFrame(wellDFList,columns=colList)\n",
    "    wellArray = np.zeros((dis.nrow, dis.ncol))\n",
    "    \n",
    "    #add the wells to the array\n",
    "    for thisRow in wellDF.itertuples():\n",
    "        row = int(getattr(thisRow, \"ROW\"))-1\n",
    "        col = int(getattr(thisRow,\"COL\"))-1\n",
    "        thisReduced = (float(getattr(thisRow,\"APPLQ\"))-float(getattr(thisRow,\"ACTQ\")))/float(getattr(thisRow,\"APPLQ\"))*100.0\n",
    "        wellArray[row,col]=thisReduced\n",
    "    \n",
    "    other_dict[\"pumpingReduction\"]=wellArray\n",
    "if len(thinList)>0:\n",
    "    cellArray = np.zeros((dis.nrow, dis.ncol))\n",
    "    #add the wells to the array\n",
    "    for thisCell in thinList:\n",
    "        row = thisCell[0]\n",
    "        col = thisCell[1]\n",
    "        cellArray[row,col]=1\n",
    "    \n",
    "    other_dict[\"thinCells\"]=cellArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbb = fp.utils.CellBudgetFile(os.path.join(model_ws,md+\".cbc\"))\n",
    "try:\n",
    "    CGWD = cbb.get_data(text=b' HEAD DEP BOUNDS')[0]\n",
    "    CGWD_DF = pd.DataFrame(CGWD)\n",
    "    CGWD_DF = CGWD_DF.rename(index=str,columns={\"node\":\"node_num\"})\n",
    "    #adjust the node numbering\n",
    "    CGWD_DF.node_num = CGWD_DF.node_num-1\n",
    "    model_grid = pd.merge(model_grid,CGWD_DF,\"left\",\"node_num\", sort=False)\n",
    "    CGWD_q = -1*model_grid.q.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict['CGWD_q'] = CGWD_q\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "#outFile = os.path.join(model_ws,\"CGWD_out2.csv\")\n",
    "#np.savetxt(outFile,CGWD,delimiter=',', header=','.join(CGWD.dtype.names), comments=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if b'          DRAINS' in cbb.get_unique_record_names():\n",
    "    Drn = cbb.get_data(text=b' DRAINS')[0]\n",
    "    Drn_DF = pd.DataFrame(Drn)\n",
    "    Drn_DF = Drn_DF.rename(index=str,columns={\"node\":\"node_num\"})\n",
    "    #adjust the node numbering\n",
    "    Drn_DF.node_num = Drn_DF.node_num-1\n",
    "    model_grid = pd.merge(model_grid,Drn_DF,\"left\",\"node_num\", sort=False)\n",
    "    if \"q_y\" in model_grid.columns:\n",
    "        Drn_q = -1*model_grid.q_y.values.reshape(dis.nrow, dis.ncol)\n",
    "    else:\n",
    "        Drn_q = -1*model_grid.q.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict['DRN_q'] = Drn_q\n",
    "\n",
    "\n",
    "    # fname = '{}.tif'.format('DRN_q')\n",
    "    # dst = os.path.join(model_ws, fname)\n",
    "    # if os.path.exists(dst):\n",
    "    #     os.remove(dst)\n",
    "    # data = DRN_q.values.reshape(dis.nrow,dis.ncol)\n",
    "    # make_raster(dst, data, dis.ncol, dis.nrow, gt, shapeproj, np.nan)\n",
    "\n",
    "\n",
    "    #outFile = os.path.join(model_ws,\"CGWD_out2.csv\")\n",
    "    #np.savetxt(outFile,CGWD,delimiter=',', header=','.join(CGWD.dtype.names), comments=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if b'          DRAINS' in cbb.get_unique_record_names():\n",
    "    fname = '{}.tif'.format('DRN_q')\n",
    "    dst = os.path.join(model_ws, fname)\n",
    "    if os.path.exists(dst):\n",
    "        os.remove(dst)\n",
    "    thisDataTemp = other_dict['DRN_q'].reshape(dis.nrow,dis.ncol)\n",
    "    thisDataTemp[np.isnan(thisDataTemp)]=0\n",
    "    thisData = os.path.join(model_ws,\"DRN_q.dat\")\n",
    "    np.savetxt(thisData, thisDataTemp, fmt='%15.6E', delimiter='')\n",
    "\n",
    "    commandTxt = '\"C:\\\\Users\\\\jbarclay\\\\.conda\\\\envs\\\\GenMod\\\\python\" \"C:\\\\Users\\\\jbarclay\\\\OneDrive - DOI\\\\LISS\\\\Analysis\\\\Python\\\\ArrayToTiff.py\" %s \"%s\" %s %s'%(md,model_ws,thisData,dst)\n",
    "\n",
    "    info = subprocess.STARTUPINFO()\n",
    "    info.dwFlags = subprocess.STARTF_USESHOWWINDOW\n",
    "    info.wShowWindow = subprocess.SW_HIDE\n",
    "\n",
    "    with subprocess.Popen(commandTxt, stdout=subprocess.PIPE, startupinfo=info, stderr = subprocess.STDOUT, bufsize=1, universal_newlines=True) as p:\n",
    "\n",
    "        for line in p.stdout:\n",
    "            print(line, end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if b'   RIVER LEAKAGE' in cbb.get_unique_record_names():\n",
    "    RIV = cbb.get_data(text=b'   RIVER LEAKAGE')[0]\n",
    "    RIV_DF = pd.DataFrame(RIV)\n",
    "    RIV_DF = RIV_DF.rename(index=str,columns={\"node\":\"node_num\"})\n",
    "    #adjust the node numbering\n",
    "    RIV_DF.node_num = RIV_DF.node_num-1\n",
    "    RIV_DF.rename(columns={'q':\"RIV_q\"}, inplace=True)\n",
    "    model_grid = pd.merge(model_grid,RIV_DF,\"left\",\"node_num\", sort=False)\n",
    "    RIV_q = -1*model_grid.RIV_q.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict['RIV_q'] = RIV_q\n",
    "\n",
    "\n",
    "#outFile = os.path.join(model_ws,\"CGWD_out2.csv\")\n",
    "#np.savetxt(outFile,CGWD,delimiter=',', header=','.join(CGWD.dtype.names), comments=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if b'  STREAM LEAKAGE' in cbb.get_unique_record_names():\n",
    "    sfr = mf.get_package('SFR')\n",
    "    SFR = cbb.get_data(text=b'  STREAM LEAKAGE')[0]\n",
    "    SFR_DF = pd.DataFrame(SFR)\n",
    "    SFR_DF = SFR_DF.rename(index=str,columns={\"node\":\"node_num\"})\n",
    "    #flatten the nodes to 1 layer\n",
    "    while np.max(SFR_DF.node_num)>(dis.nrow*dis.ncol):\n",
    "        SFR_DF.loc[SFR_DF.node_num>(dis.nrow*dis.ncol),\"node_num\"] = SFR_DF.loc[SFR_DF.node_num>(dis.nrow*dis.ncol),\"node_num\"] - (dis.nrow*dis.ncol)\n",
    "    \n",
    "    #adjust the node numbering\n",
    "    SFR_DF.node_num = SFR_DF.node_num-1\n",
    "    SFR_DF.rename(columns={'q':\"SFR_q\"}, inplace=True)\n",
    "    SFR_DF = SFR_DF.groupby([\"node_num\"],as_index=False)[\"SFR_q\"].sum()\n",
    "    model_grid = pd.merge(model_grid,SFR_DF,\"left\",\"node_num\", sort=False)\n",
    "    SFR_q = -1*model_grid.SFR_q.values.reshape(dis.nrow, dis.ncol)\n",
    "    other_dict['SFR_q'] = SFR_q\n",
    "\n",
    "\n",
    "#outFile = os.path.join(model_ws,\"CGWD_out2.csv\")\n",
    "#np.savetxt(outFile,CGWD,delimiter=',', header=','.join(CGWD.dtype.names), comments=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add the combined well flux to the model_grid\n",
    "#get the well fluxes (layers 3 & 4)\n",
    "pumpFluxes = well.stress_period_data.df[well.stress_period_data.df.k>1]\n",
    "\n",
    "#adjust the node numbering\n",
    "pumpFluxes.node = pumpFluxes.node\n",
    "\n",
    "#aggregate by cell\n",
    "pumpFluxes = pumpFluxes.groupby('node').sum()\n",
    "pumpFluxes.reset_index(inplace=True)\n",
    "model_grid = pd.merge(model_grid,pumpFluxes,\"left\",left_on=\"node_num\",right_on=\"node\",sort=False)\n",
    "\n",
    "Well_Flux = model_grid.flux0.values.reshape(dis.nrow,dis.ncol)\n",
    "other_dict['Well_Flux']=Well_Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open the grid specs file to get the xul and yul values\n",
    "grid_specs_file = os.path.join(geo_ws,\"grid_spec.txt\")\n",
    "\n",
    "o_file = open(grid_specs_file)\n",
    "marker = 0\n",
    "for line in o_file:\n",
    "    if marker==\"ul\":\n",
    "        coords = line[:-1].split()\n",
    "        marker=0\n",
    "    if marker==\"rotation\":\n",
    "        rotation = float(line[:-1].split()[1])\n",
    "        marker=0\n",
    "    if len(line)>3:\n",
    "        if line.split()[0]==\"Upper\" and line.split()[1]==\"left\":\n",
    "            marker=\"ul\"\n",
    "        if line.split()[0]==\"Rotation\":\n",
    "            marker = \"rotation\"\n",
    "o_file.close()\n",
    "\n",
    "xul = float(coords[0])\n",
    "yul = float(coords[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote CoastalCT500.shp\n"
     ]
    }
   ],
   "source": [
    "#set the spatial reference\n",
    "\n",
    "mf.sr = fp.utils.reference.SpatialReference(delr=[L]*dis.ncol, delc=[L]*dis.nrow, lenuni=dis.lenuni, xul = xul, yul = yul, rotation = rotation, units=\"meters\", proj4_str=\"EPSG:5070\")\n",
    "\n",
    "#use the prj file from the domain file\n",
    "prj = md+\"_domain.prj\"\n",
    "prj = os.path.join(geo_ws,prj)\n",
    "#temporarily change the directory\n",
    "thisDir = os.getcwd()\n",
    "os.chdir(model_ws)\n",
    "fp.export.shapefile_utils.model_attributes_to_shapefile(md+\".shp\",mf,array_dict=other_dict, prj=prj)\n",
    "\n",
    "#change the directory back\n",
    "os.chdir(thisDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noFlowDF = model_grid.loc[(model_grid.ibound==1)&(model_grid.q_y==0)&(model_grid.ghb_sea==1)&(model_grid.reachcode!=0),[\"q_y\",\"reachcode\",\"arbolateSu\",\"lake\",\"Coast_Deep\",\"Coast_Shallow\",\"fresh_head\",\"wt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.57855253e-03,   1.70962900e-01,   5.90032578e-01,\n",
       "         2.06264549e+00,   1.29283943e+01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noFlowDF['headDiff']=noFlowDF.fresh_head-noFlowDF.wt\n",
    "np.percentile(noFlowDF.headDiff,[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_num', 'node_num.1', 'node_num.1.1', 'ibound', 'SHEDS',\n",
       "       'arbolateSu', 'gess_poly', 'lake', 'kauffman_CTquat_thk',\n",
       "       'HUC12_shortCD', 'HUC12_shortCD_ext', 'sewer', 'pws', 'well_PWSFlux',\n",
       "       'well_Glacial', 'BedLithSimp', 'SurfGeo', 'embayment', 'baseflowGage',\n",
       "       'ned', 'ned_mean', 'kauffman_bedrock_el', 'slope', 'ned_coast_min',\n",
       "       'catchment', 'soller_thk', 'soller_bedrock_el', 'nlcd', 'clear',\n",
       "       'clear_per_grass', 'nlcd_ag', 'WetlandPer', 'PerDev', 'PerImp',\n",
       "       'population', 'rch_eff_m_SWB_NAWQA', 'rch_eff_m_Reitz_2013',\n",
       "       'rch_m_Wolock', 'Coast_Deep', 'Coast_Shallow', 'PerWater', 'PerSand',\n",
       "       'PerClay', 'PerSilt', 'NDep_dry', 'NDep_wet', 'edge', 'ghb', 'stage',\n",
       "       'segment_len', 'order', 'arbolateSum', 'reachcode', 'reach_intermit',\n",
       "       'reach_len', 'reach_int', 'riv_coast', 'road', 'road_length', 'ghb_sea',\n",
       "       'fresh_head', 'Coast_all', 'Coast_major', 'top', 'lay', 'row', 'col',\n",
       "       'obs_type', 'xc', 'yc', 'population_float', 'K0', 'K0_noLakes',\n",
       "       'drain_elev', 'Septic_flux', 'PrivateWell_flux', 'recharge',\n",
       "       'pre_cal_heads', 'pre_cal_K', 'thk', 'thkR', 'obs_type_int',\n",
       "       'PrivWell_flux', 'NetPrivSeptLoss', 'wt', 'q_x', 'IFACE           _x',\n",
       "       'q_y', 'IFACE           _y', 'SFR_q', 'node', 'id', 'k', 'i', 'j',\n",
       "       'flux0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00070479  0.00082496  0.000939  ]\n",
      "[ 0.          0.00078197  0.00091578]\n",
      "[ 0.00072124  0.00082911  0.00094275]\n"
     ]
    }
   ],
   "source": [
    "#mean recharge for cells with and without discharge\n",
    "RCH = rch.rech.array[0][0]-other_dict[\"Septic_flux\"]/L/L\n",
    "print(np.percentile(RCH[ibound.array[0]==1],[25,50,75]))\n",
    "print(np.percentile(RCH[(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))],[25,50,75]))\n",
    "print(np.percentile(RCH[(ibound.array[0]==1)&((CGWD_q<=0)&(Drn_q<=0))],[25,50,75]))\n",
    "COAST = model_grid.Coast_major.values.reshape(dis.nrow, dis.ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 1491)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CGWD_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drainage cell fraction of all cells\n",
      "0.129227753665\n",
      "Drainage cell fraction of cells non coastal-major cells\n",
      "0.102912505728\n",
      "Drainage cell fraction of non-septic recharge\n",
      "0.0951508985456\n",
      "Drainage cell fraction of all recharge\n",
      "0.094764\n"
     ]
    }
   ],
   "source": [
    "print(\"Drainage cell fraction of all cells\")\n",
    "print(np.sum([(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))])/np.sum([ibound.array[0]]))\n",
    "print(\"Drainage cell fraction of cells non coastal-major cells\")\n",
    "print(np.sum([(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))&(COAST==0)])/np.sum([ibound.array[0][COAST==0]]))\n",
    "print(\"Drainage cell fraction of non-septic recharge\")\n",
    "print(np.sum(RCH[(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))&(COAST==0)])/np.sum(RCH[(ibound.array[0]==1)&(COAST==0)]))\n",
    "print(\"Drainage cell fraction of all recharge\")\n",
    "print(np.sum(rch.rech.array[0][0][(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))&(COAST==0)])/np.sum(rch.rech.array[0][0][(ibound.array[0]==1)&(COAST==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within the Niantic Watershed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Niantic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-f2a15bfc2d8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Within the Niantic Watershed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNiantic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNiantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Drainage cell fraction of cells\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNiantic\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mibound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCGWD_q\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDrn_q\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNiantic\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mibound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Drainage cell fraction of non-septic recharge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jbarclay\\.conda\\envs\\genmod\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2743\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2744\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Niantic'"
     ]
    }
   ],
   "source": [
    "print(\"Within the Niantic Watershed\")\n",
    "Niantic = model_grid.Niantic.values.reshape(dis.nrow, dis.ncol)\n",
    "print(\"Drainage cell fraction of cells\")\n",
    "print(np.sum([(Niantic==1)&(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))])/np.sum([(Niantic==1)&(ibound.array[0]==1)]))\n",
    "print(\"Drainage cell fraction of non-septic recharge\")\n",
    "print(np.sum(RCH[(Niantic==1)&(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))])/np.sum(RCH[(Niantic==1)&(ibound.array[0]==1)]))\n",
    "print(\"Drainage cell fraction of all recharge\")\n",
    "print(np.sum(rch.rech.array[0][0][(Niantic==1)&(ibound.array[0]==1)&((CGWD_q>0)|(Drn_q>0))])/np.sum(rch.rech.array[0][0][(Niantic==1)&(ibound.array[0]==1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid.loc[(model_grid.ibound==1) & (pd.notnull(model_grid.stage)) & (model_grid.q_y==0),[\"order\",'q_y']].groupby(\"order\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(model_grid.stage[pd.notnull(model_grid.stage)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "239/817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in other_dict.keys():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "d625b8658e8a4bcf8f6b43f44d0fdf4a": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
