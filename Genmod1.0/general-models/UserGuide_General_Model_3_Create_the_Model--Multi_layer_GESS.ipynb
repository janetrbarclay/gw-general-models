{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a general MODFLOW model from the NHDPlus dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project specific variables are imported in the model_spec.py and gen_mod_dict.py files that must be included in the notebook directory. The first first includes pathnames to data sources that will be different for each user. The second file includes a dictionary of model-specific information such as  cell size, default hydraulic parameter values, and scenario defintion (e.g. include bedrock, number of layers, etc.). There are examples in the repository. Run the following cells up to the \"Run to here\" cell to get a pull-down menu of models in the model_dict. Then, without re-running that cell, run all the remaining cells.  Re-running the following cell would re-set the model to the first one in the list, which you probably don't want. If you use the notebook option to run all cells below, it runs the cell you're in, so if you use that option, move to the next cell (below the pull-down menu of models) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "from model_specs import *\n",
    "from gen_mod_dict import *\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy as fp\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import math\n",
    "gdal.UseExceptions()\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in model_dict.items():   # from \"gen_mod_dict.py\"\n",
    "    md = key\n",
    "    ms = model_dict[md]\n",
    "    print('trying {}'.format(md))\n",
    "    try:\n",
    "        pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = list(model_dict.keys())\n",
    "models.sort()\n",
    "model_area = Dropdown(\n",
    "    options=models,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to here to initiate notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First time using this notebook in this session (before restarting the notebook), run the cells up to this point. Then select your model from the dropdown list above. Move your cursor to this cell and use the toolbar menu Cell --> Run All Below.  After the first time, if you want to run another model, select your model and start running from this cell--you don't need to re-run the cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md = model_area.value\n",
    "ms = model_dict[md]\n",
    "print('The model being processed is {}\\n'.format(md))\n",
    "\n",
    "if 'L' in ms.keys():\n",
    "    L = ms['L']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set pathnames and create workspace directories for geographic data (from Notebook 1) and this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scenarioLabel=\"DRN0\"\n",
    "scenarioLabel=\"SFR_DRN0\"\n",
    "# scenarioLabel='DRN0_smoothDrn_GHBCorrections'\n",
    "# scenarioLabel=\"DRN0_sdBed150\"\n",
    "#other options: RIV, DeepBed, ShallowBed, sdBed\n",
    "#DRN and a value is needed to add drains to waterbodies off the flowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if scenarioLabel!='':\n",
    "    scenario_dir = scenario_dir+\"_\"+str(scenarioLabel)\n",
    "geo_ws = os.path.join(proj_dir, ms['ws'])\n",
    "model_ws = os.path.join(geo_ws, scenario_dir)\n",
    "array_pth = os.path.join(model_ws, 'arrays')\n",
    "    \n",
    "try:\n",
    "    shutil.rmtree(array_pth)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(model_ws)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not os.path.isdir(model_ws):\n",
    "    os.makedirs(model_ws)\n",
    "\n",
    "\n",
    "head_file_name = '{}.hds'.format(md)\n",
    "head_file_pth = os.path.join(model_ws, head_file_name)\n",
    "\n",
    "print (model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace entries from the default K_dict with the model specific K values from model_dict if they exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from \"gen_mod_dict.py\"\n",
    "for key, value in K_dict.items():\n",
    "    if key in ms.keys():\n",
    "        K_dict[key] = ms[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace entries from the default rock_riv_dict with the model specific values from model_dict if they exist. rock_riv_dict has various attributes of bedrock and stream geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from \"gen_mod_dict.py\"\n",
    "for key, value in rock_riv_dict.items():\n",
    "    if key in ms.keys():\n",
    "        rock_riv_dict[key] = ms[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign values to variables used in this notebook using rock_riv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_thk = rock_riv_dict['min_thk'] \n",
    "stream_width = rock_riv_dict['stream_width'] \n",
    "stream_bed_thk = rock_riv_dict['stream_bed_thk']\n",
    "river_depth = rock_riv_dict['river_depth'] \n",
    "bedrock_thk = rock_riv_dict['bedrock_thk']\n",
    "# addition of stream_bed_kadjust factor by Leon Kauffman\n",
    "stream_bed_kadjust = rock_riv_dict['stream_bed_kadjust']\n",
    "\n",
    "#read in the marine boundary information\n",
    "coastal_sed_kadjust = rock_riv_dict['coastal_sed_kadjust']\n",
    "coastal_sed_thk = rock_riv_dict['coastal_sed_thk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the information for a model domain processed using Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the model_grid data frame from a csv file. Extract grid dimensions and ibound array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = os.path.join(geo_ws, 'model_grid.csv')\n",
    "model_grid = pd.read_csv(model_file, index_col='node_num', na_values=['nan', hnoflo])\n",
    "\n",
    "NROW = model_grid.row.max() + 1\n",
    "NCOL = model_grid.col.max() + 1\n",
    "num_cells = NROW * NCOL\n",
    "\n",
    "#fix a weird boundary cell in the 500ft model\n",
    "if md==\"CoastalCT500\":\n",
    "    model_grid.loc[(model_grid.row==112)&(model_grid.col==423),\"ibound\"]=0\n",
    "\n",
    "ibound = model_grid.ibound.values.reshape(NROW, NCOL)\n",
    "inactive = (ibound == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(model_grid.fresh_head[model_grid.ghb_sea==1],[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_grid.loc[model_grid.fresh_head<0,[\"ned_mean\",\"ned_coast_min\",\"fresh_head\",\"ghb_sea\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid.fresh_head.loc[model_grid.fresh_head<0]=model_grid.fresh_head.loc[model_grid.fresh_head<0].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid.reset_index(inplace=True, drop=False)\n",
    "model_grid.set_index(inplace=True,drop=False,keys=\"node_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct the top elevations for cells with drains / ghb to ensure they slope downward (this is now in NB 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thisPerWaterMin = 1\n",
    "# if \"DRN\" in scenarioLabel:\n",
    "#     thisLabel = scenarioLabel.split(\"_\")\n",
    "#     thisLabel = [x for x in thisLabel if \"DRN\" in x]\n",
    "#     thisPerWaterMin = float(thisLabel[0].replace(\"DRN\",\"\"))/100\n",
    "\n",
    "# elevationsToCheck = (model_grid.ibound==1)&((model_grid.fresh_head>0) | (np.isfinite(model_grid.stage)) | (model_grid.PerWater>thisPerWaterMin))\n",
    "# elevData = model_grid.loc[elevationsToCheck,[\"node_num\",\"top\"]]\n",
    "# #sort through the cells from highest to lowest\n",
    "# elevData.sort_values(\"top\",ascending=False,inplace=True)\n",
    "# nodeList = [x for x in elevData.node_num]\n",
    "# print(len(nodeList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def checkNeighbors(thisNode):\n",
    "#     thisRow = model_grid.loc[model_grid.node_num==thisNode,\"row\"].values[0]\n",
    "#     thisCol = model_grid.loc[model_grid.node_num==thisNode,\"col\"].values[0]\n",
    "#     thisTop = model_grid.loc[model_grid.node_num==thisNode,\"top\"].values[0]\n",
    "#     #neighbors only include the 4 adjacent cells (not the corners)\n",
    "#     neighbors = model_grid.loc[((model_grid.row==thisRow)|(model_grid.col==thisCol))&(model_grid.row>=thisRow-1)&(model_grid.row<=thisRow+1)&(model_grid.col>=thisCol-1)&(model_grid.col<=thisCol+1),['ibound','top','row','col']]\n",
    "#     if np.any(neighbors.ibound==0):\n",
    "#     #     continue\n",
    "#         newMin = -9999\n",
    "#         newNodes = []\n",
    "#     else:\n",
    "#         if neighbors[neighbors.top<=thisTop].shape[0]>1:\n",
    "#     #         continue\n",
    "#             newMin = -9999\n",
    "#             newNodes = []\n",
    "#         else:\n",
    "#             #get the minimum neighbor\n",
    "#             newMin = np.min(neighbors.top[neighbors.top!=thisTop])\n",
    "# #             print(\"Row: %s, Col: %s\"%(str(thisRow),str(thisCol)))\n",
    "# #             print(\"New Min: %s, Old Min: %s\"%(str(newMin),str(thisTop)))\n",
    "# #             print(thisNode)\n",
    "#             newNodes = [x for x in neighbors.index.values]\n",
    "#             #update the elevation\n",
    "#             model_grid.loc[model_grid.node_num==thisNode,\"top\"]=newMin\n",
    "            \n",
    "#             if model_grid.loc[model_grid.node_num==thisNode,\"fresh_head\"].values[0]>0:\n",
    "#                 model_grid.loc[model_grid.node_num==thisNode,\"fresh_head\"]=newMin\n",
    "#             elif np.isfinite(model_grid.loc[model_grid.node_num==thisNode,\"stage\"].values[0]):\n",
    "#                 model_grid.loc[model_grid.node_num==thisNode,\"stage\"]=newMin\n",
    "    \n",
    "#     return newMin,newNodes\n",
    "\n",
    "\n",
    "# for thisNode in nodeList:\n",
    "#     if np.where(nodeList==thisNode)[0][0]%10000==0:\n",
    "#         print(np.where(nodeList==thisNode)[0][0])\n",
    "#     # thisNode = 63181    \n",
    "#     nodesToCheck = True\n",
    "#     newMin,newNodes = checkNeighbors(thisNode)\n",
    "#     if len(newNodes)==0:\n",
    "#         nodesToCheck = False\n",
    "#     nodeList2 = newNodes\n",
    "#     nodeList2 = [x for x in nodeList2 if x!= thisNode]\n",
    "#     while nodesToCheck:\n",
    "#         thisNode = nodeList2[0]\n",
    "#         newMin,newNodes = checkNeighbors(thisNode)\n",
    "#         nodeList2.extend(newNodes)\n",
    "#         nodeList2 = np.unique(nodeList2)\n",
    "#         nodeList2 = [x for x in nodeList2 if x != thisNode]\n",
    "#         if len(nodeList2)==0:\n",
    "#             nodesToCheck = False\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate geologic information into hydrologic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get starting heads from top elevations. The top is defined as the model-cell-mean NED elevation except in streams, where it is interpolated between MaxElevSmo and MinElevSmo in the NHD (called 'stage' in model_grid). Make them a little higher than land so that drains don't accidentally go dry too soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"SFRtest\" in scenarioLabel:\n",
    "    top = model_grid.ned_mean.values.reshape(NROW, NCOL)\n",
    "    strt = top * 1.05\n",
    "else:\n",
    "    top = model_grid.top.values.reshape(NROW, NCOL)\n",
    "    strt = top * 1.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the bedrock surface, ensuring that it is always at least min_thk below the top elevation. This calculation will be revisited for the multi-layer case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bedrock = model_grid.kauffman_bedrock_el.values.reshape(NROW, NCOL)\n",
    "# thick = model_grid.kauffman_CTquat_thk.values.reshape(NROW,NCOL)\n",
    "\n",
    "thk = top - bedrock\n",
    "\n",
    "if \"sdBed\" in scenarioLabel:\n",
    "    thisLabel = scenarioLabel.split(\"_\")\n",
    "    thisLabel = [x for x in thisLabel if \"sdBed\" in x]\n",
    "    thisPer = float(thisLabel[0].replace(\"sdBed\",\"\"))/100\n",
    "    thk = (thk-np.nanmean(thk[ibound==1]))*thisPer+np.nanmean(thk[ibound==1])\n",
    "    bedrock = top -thk\n",
    "\n",
    "if \"ShallowBed\" in scenarioLabel:\n",
    "    thk = thk*0.5\n",
    "    bedrock = top - thk\n",
    "elif \"DeepBed\" in scenarioLabel:\n",
    "    thk = thk*1.5\n",
    "    bedrock = top - thk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for geology mapping to zone number from dataset GESS_poly.gdb in\n",
    "\"Glacial Environments and Surficial Sediments (GESS) Geodatabase for the Glaciated, Conterminous United States\",\n",
    "https://doi.org/10.5066/F71R6PQG\n",
    "\n",
    "model_grid.gess_poly from CrseStratSed in GESS_poly.gdb = 0 represents fine sediments\n",
    "\n",
    "model_grid.gess_poly from CrseStratSed in GESS_poly.gdb = 1 represents coarse sediments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary that maps the K_dict from gen_mod_dict to zone numbers (key=zone number, value=entry in K_dict).  Make sure these correspond with the correct units. If you're using the defaults, it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zone_dict = {0 : 'K_fine', 1 : 'K_coarse', 2 : 'K_lakes', 3 : 'K_bedrock'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the mapping from zone number to K to create the Kh1d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones1d = np.zeros(( NROW, NCOL ), dtype=np.int32)\n",
    "\n",
    "gess = model_grid.gess_poly.values.reshape( NROW, NCOL )\n",
    "zones1d[gess == 0] = 0\n",
    "zones1d[gess == 1] = 1\n",
    "zones1d[thk<(min_thk/2)]=3\n",
    "zones1d_noLakes = deepcopy(zones1d)\n",
    "\n",
    "la = model_grid.lake.values.reshape( NROW, NCOL )\n",
    "zones1d[la == 1] = 2\n",
    "\n",
    "\n",
    "\n",
    "Kh1d = np.zeros(( NROW, NCOL ), dtype=np.float32)\n",
    "Kh1d_noLakes = np.zeros(( NROW, NCOL ), dtype=np.float32)\n",
    "\n",
    "for key, val in zone_dict.items():\n",
    "    Kh1d[zones1d == key] = K_dict[val]\n",
    "    Kh1d_noLakes[zones1d_noLakes == key] = K_dict[val]\n",
    "    \n",
    "model_grid['K0'] = Kh1d.ravel()\n",
    "model_grid['K0_noLakes'] = Kh1d_noLakes.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update the hydraulic conductivity and zone for bedrock outcrops\n",
    "\n",
    "thk[thk < min_thk] = min_thk\n",
    "bot = top - thk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process boundary condition information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of stream information for the drain or river package.\n",
    "River package input also needs the elevation of the river bed. Don't use both packages. The choice is made by commenting/uncommenting sections of the modflow function. Replace segment_len (segment length) with the conductance. The river package has not been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing the use of drn for 1st to 5th order and riv for 6th order rivers\n",
    "#& (model_grid.order<6)\n",
    "\n",
    "#make a column for the drain elevation\n",
    "model_grid['drain_elev']=model_grid.stage\n",
    "\n",
    "if \"RIV\" in scenarioLabel:\n",
    "    drn_flag = (pd.notnull(model_grid.stage)) & (model_grid.ibound == 1) & (model_grid.order<6)&(model_grid.ghb_sea==0)\n",
    "else:\n",
    "    drn_flag = (pd.notnull(model_grid.stage)) & (model_grid.ibound == 1)&(model_grid.ghb_sea==0)\n",
    "drn_data = model_grid.loc[drn_flag, ['lay', 'row', 'col', 'stage', 'segment_len', 'K0_noLakes','arbolateSum','PerWater']]\n",
    "drn_data.columns = ['k', 'i', 'j', 'stage', 'segment_len', 'K0','arbolateSu','PerWater']\n",
    "# dcond = drn_data.K0 * drn_data.segment_len * stream_width / stream_bed_thk\n",
    "# addition of stream_bed_kadjust factor by Leon Kauffman\n",
    "# stream width based on relationship from NE streams in NWIS (UU:\\R_Code\\StreamwidthRelationship.r)\n",
    "# math notes on 1/14/2020\n",
    "stream_width = math.exp(-0.20) * (drn_data.arbolateSu) **0.5594\n",
    "strm_Area = stream_width * drn_data.segment_len.values\n",
    "water_Area = drn_data.PerWater.values * L * L\n",
    "drn_Area = np.maximum(strm_Area,water_Area)\n",
    "dcond = drn_data.K0 * stream_bed_kadjust * drn_Area / stream_bed_thk \n",
    "drn_data['segment_len'] = dcond\n",
    "drn_data.rename(columns={'segment_len' : 'cond'}, inplace=True)\n",
    "drn_data.drop('K0', axis=1, inplace=True)\n",
    "drn_data.drop('arbolateSu',axis=1, inplace=True)\n",
    "drn_data.drop('PerWater',axis=1, inplace=True)\n",
    "drn_data.dropna(axis='index', inplace=True)\n",
    "drn_data.insert(drn_data.shape[1], 'iface', 6)\n",
    "drn_recarray = drn_data.to_records(index=False)\n",
    "drn_dict = {0 : drn_recarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ensure the drain elevations are above the bottom of the cells\n",
    "stg = model_grid.drain_elev.values.reshape(NROW, NCOL)\n",
    "stg[stg<-100000]=1.E+30\n",
    "stg[np.isnan(stg)]=1.E+30\n",
    "tmpdrn = stg.ravel()\n",
    "tmpbot = bot.ravel()\n",
    "index = np.less(tmpdrn, tmpbot)\n",
    "tmpbot[index] = tmpdrn[index] - 1.0\n",
    "bot = tmpbot.reshape(NROW, NCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing adding a drain to wetlands and lakes\n",
    "if \"DRN\" in scenarioLabel:\n",
    "    thisLabel = scenarioLabel.split(\"_\")\n",
    "    thisLabel = [x for x in thisLabel if \"DRN\" in x]\n",
    "    thisPer = float(thisLabel[0].replace(\"DRN\",\"\"))/100\n",
    "    drn_flag = (model_grid.PerWater> thisPer) & (model_grid.ibound == 1) & (pd.isnull(model_grid.stage)) & (model_grid.ghb_sea==0)\n",
    "    drn_data = model_grid.loc[drn_flag, ['lay', 'row', 'col', 'top','K0_noLakes','PerWater','node_num']]\n",
    "    drn_data.columns = ['k', 'i', 'j', 'stage', 'K0','PerWater','node_num']\n",
    "\n",
    "    #adjust the stage to ensure it is below the land surface\n",
    "    drn_data.stage = np.around(np.floor(drn_data.stage*1000)/1000.0,decimals=3)\n",
    "    \n",
    "    #update the drain elevation column\n",
    "    model_grid.loc[drn_flag,\"drain_elev\"]=drn_data.stage\n",
    "\n",
    "    dcond = drn_data.K0 * stream_bed_kadjust * L*L *drn_data.PerWater/ stream_bed_thk \n",
    "    drn_data['K0'] = dcond\n",
    "    drn_data['K0'] = drn_data['K0'].astype('float64')\n",
    "    drn_data.rename(columns={'K0' : 'cond'}, inplace=True)\n",
    "    drn_data.drop('PerWater', axis=1, inplace=True)\n",
    "    drn_data.drop('node_num', axis=1, inplace=True)\n",
    "    drn_data.dropna(axis='index', inplace=True)\n",
    "    drn_data.insert(drn_data.shape[1], 'iface', 6)\n",
    "    drn_recarray = drn_data.to_records(index=False)\n",
    "    drn_dict[0] = np.core.records.fromrecords((np.concatenate([drn_dict[0],drn_recarray], axis=0)), dtype=drn_recarray.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riv_flag = pd.notnull(model_grid.stage) & (model_grid.ibound == 1)\n",
    "riv_data = model_grid.loc[riv_flag, ['lay', 'row', 'col', 'stage', 'segment_len', 'K0_noLakes','arbolateSum','PerWater']]\n",
    "riv_data.columns = ['k', 'i', 'j', 'stage', 'segment_len', 'K0','arbolateSu','PerWater']\n",
    "riv_data['rbot'] = riv_data.stage - river_depth\n",
    "# stream width based on relationship from NE streams in NWIS (UU:\\R_Code\\StreamwidthRelationship.r)\n",
    "stream_width = math.exp(-0.20) * (riv_data.arbolateSu) **0.5594\n",
    "strm_Area = stream_width * riv_data.segment_len.values\n",
    "# water_Area = riv_data.PerWater.values * L * L\n",
    "# riv_Area = np.maximum(strm_Area,water_Area)\n",
    "#rcond = riv_data.K0 * riv_data.segment_len * stream_width / stream_bed_thk\n",
    "# addition of stream_bed_kadjust factor by Leon Kauffman\n",
    "#decreases the conductivity in large rivers by half\n",
    "rcond = riv_data.K0 * stream_bed_kadjust * strm_Area / stream_bed_thk/2\n",
    "riv_data['segment_len'] = rcond\n",
    "riv_data.rename(columns={'segment_len' : 'rcond'}, inplace=True)\n",
    "riv_data.drop('K0', axis=1, inplace=True)\n",
    "riv_data.drop('arbolateSu', axis=1, inplace=True)\n",
    "riv_data.drop('PerWater', axis=1, inplace=True)\n",
    "riv_data.dropna(axis='index', inplace=True)\n",
    "riv_data.insert(riv_data.shape[1], 'iface', 6)\n",
    "riv_recarray = riv_data.to_records(index=False)\n",
    "riv_dict = {0 : riv_recarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riv_flag = pd.notnull(model_grid.stage) & (model_grid.ibound == 1) & (model_grid.order>=6)\n",
    "riv_data = model_grid.loc[riv_flag, ['lay', 'row', 'col', 'stage', 'segment_len', 'K0_noLakes','arbolateSum','PerWater']]\n",
    "riv_data.columns = ['k', 'i', 'j', 'stage', 'segment_len', 'K0','arbolateSu','PerWater']\n",
    "riv_data['rbot'] = riv_data.stage - river_depth\n",
    "# stream width based on relationship from NE streams in NWIS (UU:\\R_Code\\StreamwidthRelationship.r)\n",
    "stream_width = math.exp(-0.20) * (riv_data.arbolateSu) **0.5594\n",
    "strm_Area = stream_width * riv_data.segment_len.values\n",
    "water_Area = riv_data.PerWater.values * L * L\n",
    "riv_Area = np.maximum(strm_Area,water_Area)\n",
    "#rcond = riv_data.K0 * riv_data.segment_len * stream_width / stream_bed_thk\n",
    "# addition of stream_bed_kadjust factor by Leon Kauffman\n",
    "#decreases the conductivity in large rivers by half\n",
    "rcond = riv_data.K0 * stream_bed_kadjust * riv_Area / stream_bed_thk/2\n",
    "riv_data['segment_len'] = rcond\n",
    "riv_data.rename(columns={'segment_len' : 'rcond'}, inplace=True)\n",
    "riv_data.drop('K0', axis=1, inplace=True)\n",
    "riv_data.drop('arbolateSu', axis=1, inplace=True)\n",
    "riv_data.drop('PerWater', axis=1, inplace=True)\n",
    "riv_data.dropna(axis='index', inplace=True)\n",
    "riv_data.insert(riv_data.shape[1], 'iface', 6)\n",
    "riv_recarray = riv_data.to_records(index=False)\n",
    "riv_dict = {0 : riv_recarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of information for the general-head boundary package.\n",
    "Similar to the above cell. Not tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if model_grid.ghb.sum() > 0:\n",
    "    ghb_flag = model_grid.ghb == 1\n",
    "    ghb_data = model_grid.loc[ghb_flag, ['lay', 'row', 'col', 'top', 'segment_len', 'K0_noLakes']]\n",
    "    ghb_data.columns = ['k', 'i', 'j', 'stage', 'segment_len', 'K0']\n",
    "    gcond = ghb_data.K0 * L * L / stream_bed_thk\n",
    "    ghb_data['segment_len'] = gcond\n",
    "    ghb_data.rename(columns={'segment_len' : 'cond'}, inplace=True)\n",
    "    ghb_data.drop('K0', axis=1, inplace=True)\n",
    "    ghb_data.dropna(axis='index', inplace=True)\n",
    "    ghb_data.insert(ghb_data.shape[1], 'iface', 6)\n",
    "    ghb_recarray = ghb_data.to_records(index=False)\n",
    "    ghb_dict = {0 : ghb_recarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for the marine general-head boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if model_grid.ghb_sea.sum() > 0:\n",
    "    #update the coastal_major\n",
    "    model_grid.loc[model_grid.HUC12_shortCD!=0,\"Coast_major\"]=0\n",
    "    \n",
    "    #currently the marine ghb would overwrite any existing ghb, therefore write an alert\n",
    "    if GHB & GHB_sea:\n",
    "        GHB = False\n",
    "        print(\"Code doesn't support multiple ghb's. Marine ghb will be implemented.\")    \n",
    "    ghb_flag = (model_grid.ghb_sea == 1)&(model_grid.ibound==1)\n",
    "    ghb_sea_data = model_grid.loc[ghb_flag, ['lay', 'row', 'col', 'order','fresh_head','segment_len','arbolateSum', 'K0_noLakes','Coast_Shallow','Coast_Deep','WetlandPer','PerWater',\"Coast_major\"]]\n",
    "    ghb_sea_data.columns = ['k', 'i', 'j', 'order','stage', 'segment_len','arbolateSum', 'K0','Coast_Shallow','Coast_Deep','WetlandPer','PerWater','Coast_major']\n",
    "    ghb_sea_data['Coast_All']=ghb_sea_data.Coast_Shallow + ghb_sea_data.Coast_Deep\n",
    "    #use PerWater for cells where both Coast_Shallow and Coast_Deep = 0 (a few cells where mapping to the coastal boundary missed some areas)\n",
    "    ghb_sea_data.loc[ghb_sea_data.Coast_All==0,\"Coast_All\"]=ghb_sea_data.loc[ghb_sea_data.Coast_All==0,\"PerWater\"]\n",
    "    ghb_sea_data['Coast_Wetland']=np.minimum(ghb_sea_data.WetlandPer,ghb_sea_data.Coast_All)\n",
    "    ghb_sea_data['Coast_nonWetland']=ghb_sea_data.Coast_All-ghb_sea_data.Coast_Wetland\n",
    "    \n",
    "    #multiplying the conductance by the coastal area and decreasing the conductance of coastal wetlands by 50%\n",
    "    gcond = K_dict['K_streambed'] * L * L / coastal_sed_thk / coastal_sed_kadjust*(ghb_sea_data.Coast_nonWetland\n",
    "    + 0.25*ghb_sea_data.Coast_Wetland)\n",
    "    \n",
    "    #also using the streambed area (for cells without mapped wetlands)\n",
    "    stream_width = math.exp(-0.20) * (ghb_sea_data.arbolateSum) **0.5594\n",
    "    strm_Area = stream_width * ghb_sea_data.segment_len.values\n",
    "    dcond = K_dict['K_streambed']* strm_Area/ coastal_sed_thk / coastal_sed_kadjust\n",
    "    #set null values to 0 so they are always smaller\n",
    "    dcond[pd.isnull(dcond)]=0\n",
    "    coastCond = np.maximum(gcond,dcond)\n",
    "    ghb_sea_data['segment_len'] = coastCond\n",
    "    ghb_sea_data.rename(columns={'segment_len' : 'cond'}, inplace=True)\n",
    "    ghb_sea_data.drop('K0', axis=1, inplace=True)\n",
    "    ghb_sea_data.drop('Coast_Shallow',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('Coast_Deep',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('WetlandPer',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('PerWater',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('Coast_All',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('Coast_Wetland',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('Coast_nonWetland',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('arbolateSum',axis=1,inplace=True)\n",
    "    ghb_sea_data.insert(ghb_sea_data.shape[1], 'iface', 6)\n",
    "    if inlandCoastalAsDrains:\n",
    "        coastalDrains = ghb_sea_data[ghb_sea_data.Coast_major==0]\n",
    "        coastalDrains.drop('Coast_major',axis=1,inplace=True)\n",
    "        \n",
    "        if \"RIV\" in scenarioLabel:\n",
    "            rivData = coastalDrains[coastalDrains.order>=6]\n",
    "            rivData['rbot'] = rivData.stage - river_depth\n",
    "            rivData.dropna(axis='index', inplace=True)\n",
    "            rivData.drop('order',axis=1,inplace=True)\n",
    "            rivData.dropna(axis='index', inplace=True)\n",
    "            rivData = rivData[[\"k\",\"i\",\"j\",\"stage\",\"cond\",\"rbot\",\"iface\"]]\n",
    "            rivData.cond = rivData.cond/2 #decreases the conductivity for large rivers\n",
    "            rivData.rename(columns={'cond' : 'rcond'}, inplace=True)\n",
    "            riv_recarray2 = rivData.to_records(index=False)\n",
    "            riv_dict[0] = np.core.records.fromrecords((np.concatenate([riv_dict[0],riv_recarray2], axis=0)), dtype=riv_recarray.dtype)\n",
    "            coastalDrains = coastalDrains.loc[np.isnan(coastalDrains.order) | (coastalDrains.order<6)]\n",
    "        coastalDrains.drop('order',axis=1,inplace=True)\n",
    "        coastalDrains.dropna(axis='index', inplace=True)\n",
    "        \n",
    "        drn_flag = deepcopy(ghb_flag)\n",
    "        drn_flag = drn_flag & (model_grid.Coast_major==0)\n",
    "        \n",
    "        #update the drain elevation column\n",
    "        model_grid.loc[drn_flag,\"drain_elev\"]=coastalDrains.stage\n",
    "        \n",
    "        drn_recarray = coastalDrains.to_records(index=False)\n",
    "        drn_dict[0] = np.core.records.fromrecords((np.concatenate([drn_dict[0],drn_recarray], axis=0)), dtype=drn_recarray.dtype)\n",
    "        \n",
    "        ghb_sea_data = ghb_sea_data[ghb_sea_data.Coast_major==1]\n",
    "    ghb_sea_data.drop('Coast_major',axis=1,inplace=True)\n",
    "    ghb_sea_data.drop('order',axis=1,inplace=True)\n",
    "    ghb_sea_data.dropna(axis='index', inplace=True)\n",
    "    ghb_sea_recarray = ghb_sea_data.to_records(index=False)\n",
    "    ghb_sea_dict = {0 : ghb_sea_recarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to correct populations that are below the threshold (aggregating them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(model_grid.population[model_grid.ibound==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first, get a list of cells with non-zero populations below the threshold\n",
    "lowPop = (model_grid.population<popThreshold)&(model_grid.ibound==1)&(model_grid.population!=0)\n",
    "lowPopCells = model_grid.loc[lowPop,[\"node_num\",\"population\",\"row\",\"col\",\"road\",\"road_length\"]]\n",
    "thisCountMax = np.sum(lowPop)\n",
    "print(thisCountMax)\n",
    "for thisCount in range(thisCountMax):\n",
    "\n",
    "    if lowPopCells.shape[0]==0:\n",
    "        break\n",
    "\n",
    "    if thisCount%500==0:\n",
    "        print(lowPopCells.shape[0])\n",
    "    lowPopCellsClip = lowPopCells[lowPopCells.population==np.min(lowPopCells.population)]\n",
    "    lowPopCellsClip = lowPopCellsClip.sort_values(by=['population','road','road_length'])\n",
    "    thisRow = lowPopCellsClip.row.values[0]\n",
    "    thisCol = lowPopCellsClip.col.values[0]\n",
    "    #get a cluster of low population cells, with the initial cluster size based on the grid resolution\n",
    "    ncells = 0\n",
    "    if L==500*ft2m:\n",
    "        ncells = 1\n",
    "    elif L==250*ft2m:\n",
    "        ncells = 2\n",
    "    lowRow = thisRow-ncells\n",
    "    highRow = thisRow+ncells\n",
    "    lowCol = thisCol-ncells\n",
    "    highCol = thisCol+ncells\n",
    "    cellFlag = (lowPopCells.row>=lowRow)&(lowPopCells.row<=highRow)&(lowPopCells.col>=lowCol)&(lowPopCells.col<=highCol)\n",
    "    thisCell = lowPopCells[cellFlag]\n",
    "    \n",
    "    #ensure that the sum of the population from the cluster is < the threshold\n",
    "    while np.sum(thisCell.population)>popThreshold:\n",
    "        ncells = ncells - 1\n",
    "        thisCell = lowPopCells.loc[(lowPopCells.row>=(thisRow-ncells))&(lowPopCells.row<=(thisRow+ncells))&(lowPopCells.col>=(thisCol-ncells))&(lowPopCells.col<=(thisCol+ncells))]\n",
    "\n",
    "    for thisRange in range(10):\n",
    "        lowRow = thisRow-(thisRange+ncells)\n",
    "        highRow = thisRow+(thisRange+ncells)\n",
    "        lowCol = thisCol-(thisRange+ncells)\n",
    "        highCol = thisCol+(thisRange+ncells)\n",
    "        nearbyCells = model_grid.loc[~(model_grid.node_num.isin(thisCell.node_num))&(model_grid.row>=lowRow)&(model_grid.row<=highRow)&(model_grid.col>=lowCol)&(model_grid.col<=highCol)&(model_grid.population!=0),[\"node_num\",\"population\",\"row\",\"col\",\"road\",\"road_length\"]]\n",
    "        \n",
    "        if nearbyCells.shape[0]==0:\n",
    "            continue\n",
    "\n",
    "        nearbyCells['Distance']=np.sqrt(np.abs(nearbyCells.row-thisRow)^2+np.abs(nearbyCells.col-thisCol)^2)\n",
    "\n",
    "        nearbyCells=nearbyCells.sort_values(by=['road','population','road_length','Distance'],ascending=False)\n",
    "        newNode = nearbyCells.node_num.values[0]\n",
    "\n",
    "        #copy the current cell's population to the new cells population\n",
    "        thisPop = np.sum(thisCell.population)\n",
    "        model_grid.loc[model_grid.node_num==newNode,\"population\"]=model_grid.loc[model_grid.node_num==newNode,\"population\"]+thisPop\n",
    "        lowPopCells.loc[lowPopCells.node_num==newNode,\"population\"]=model_grid.loc[model_grid.node_num==newNode,\"population\"]\n",
    " \n",
    "        #set the current cell's population to 0\n",
    "        model_grid.loc[model_grid.node_num.isin(thisCell.node_num.values),\"population\"]=0\n",
    "        break\n",
    "\n",
    "    cellsToRemove = [x for x in thisCell.node_num.values]\n",
    "    if model_grid.loc[model_grid.node_num==newNode,\"population\"].values[0]>popThreshold:\n",
    "        cellsToRemove.append(newNode)\n",
    "    lowPopCells = lowPopCells[~lowPopCells.node_num.isin(cellsToRemove)]\n",
    "    lowPop = (lowPopCells.population<popThreshold)&(lowPopCells.population!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.min(model_grid.population[(model_grid.ibound==1)&(model_grid.population!=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for septic systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_grid.sewer.sum() > 0:\n",
    "    septic_flag = (model_grid.sewer == 0)&(model_grid.ibound==1)\n",
    "    septic_data = model_grid.loc[:, ['lay', 'row', 'col', 'population','sewer','PerWater']]\n",
    "    septic_data.columns = ['k', 'i', 'j', 'population','sewer','PerWater']\n",
    "    \n",
    "    #use the percent water to adjust the population density\n",
    "    septic_data['population'] = septic_data.population*(1-septic_data.PerWater)\n",
    "    \n",
    "    #set septic recharge to the top layer\n",
    "    septic_data['k']=0\n",
    "    septic_flux = septic_data.population*useResPerCap*(1-consumpRes)*(1-septic_data.sewer)\n",
    "    septic_data['Q'] = septic_flux\n",
    "    model_grid.loc[:, 'Septic_flux']=septic_flux\n",
    "    #septic_data.drop('population', axis=1, inplace=True)\n",
    "    #septic_data.dropna(axis='index', inplace=True)\n",
    "    #septic_recarray = septic_data.to_records(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for private wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_grid.pws.sum() > 0:\n",
    "    well_flag = (model_grid.pws == 0)&(model_grid.ibound==1)\n",
    "    well_data = model_grid.loc[:, ['lay', 'row', 'col', 'population','pws','PerWater']]\n",
    "    well_data.columns = ['k', 'i', 'j', 'population','pws',\"PerWater\"]\n",
    "    \n",
    "    #use the percent water to adjust the population density\n",
    "#     well_data['population'] = well_data.population*(1-well_data.PerWater)\n",
    "    \n",
    "    #set well withdrawals to the bottom layer\n",
    "    well_data['k']= num_surf_layers\n",
    "    well_flux = well_data.population*useResPerCap*(1-well_data.pws)\n",
    "    well_data['Q'] = -1*well_flux #negative flux is pumping\n",
    "    model_grid.loc[:, 'PrivateWell_flux']=-1*well_flux\n",
    "    well_data.drop('population', axis=1, inplace=True)\n",
    "    well_data.drop('PerWater', axis=1, inplace=True)\n",
    "    well_data.drop('pws', axis=1, inplace=True)\n",
    "    well_data.dropna(axis='index', inplace=True)\n",
    "    well_recarray = well_data.to_records(index=False)\n",
    "    well_dict={0:well_recarray}\n",
    "    #well_dict[0] = np.append(well_dict[0],well_recarray, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for water supply wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_grid.well_PWSFlux.sum() != 0:\n",
    "    well_flag = (model_grid.well_PWSFlux != 0)&(model_grid.ibound==1)\n",
    "    well_data = model_grid.loc[well_flag, ['lay', 'row', 'col', 'well_PWSFlux','well_Glacial']]\n",
    "    well_data.columns = ['k', 'i', 'j', 'Q','well_Glacial']\n",
    "    #set well withdrawals to the bottom layer (or the lowest surf layer if it is a glacial well (based on specified aquifer or APA))\n",
    "    well_data['k']= num_surf_layers-well_data['well_Glacial'].astype('int64')\n",
    "    well_data.drop('well_Glacial', axis=1, inplace=True)\n",
    "    well_data.dropna(axis='index', inplace=True)\n",
    "    well_recarray = well_data.to_records(index=False)\n",
    "    #well_dict={0:well_recarray}\n",
    "    well_dict[0] = np.append(well_dict[0],well_recarray, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ensure the bottom of the top layer is at or below the bottom of all drains and ghb boundaries\n",
    "ghb = deepcopy(model_grid.fresh_head.values.reshape(NROW,NCOL))\n",
    "ghb_sea = ghb_sea = model_grid.ghb_sea.values.reshape(NROW,NCOL)\n",
    "ghb[ghb_sea==0]=100000\n",
    "bot = np.minimum(bot,ghb)\n",
    "bot[bot==ghb]=bot[bot==ghb]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create recharge array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid.to_csv(os.path.join(model_ws, 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version replaces the Wolock/Yager recharge grid and the Reitz grid with the SWB_NAWQA. An alternative recharge source can also be specified (Wolock)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## used in general models prior to 4/5/2016\n",
    "# rech = model_grid.recharge.values.reshape(NROW, NCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace rech array with\n",
    "* calculate total recharge for the model domain\n",
    "* calculate areas of fine and coarse deposits\n",
    "* apportion recharge according to the ratio specified in gen_mod_dict.py\n",
    "* write the values to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now using an alternate approach below\n",
    "# r_SWB = model_grid.rch_eff_m_SWB_NAWQA.values.reshape(NROW, NCOL) / 365.25\n",
    "\n",
    "# rech_ma = np.ma.MaskedArray(r_SWB, mask=inactive)\n",
    "# coarse_ma = np.ma.MaskedArray(zones1d != 0, mask=inactive)\n",
    "# fine_ma = np.ma.MaskedArray(zones1d == 0, mask=inactive)\n",
    "\n",
    "# total_rech = rech_ma.sum()\n",
    "# Af = fine_ma.sum()\n",
    "# Ac = coarse_ma.sum()\n",
    "# Rf = total_rech / (rech_fact * Ac + Af)\n",
    "# Rc = rech_fact * Rf\n",
    "\n",
    "# rech = np.zeros_like(r_SWB)\n",
    "# rech[zones1d != 0] = Rc\n",
    "# rech[zones1d == 0] = Rf\n",
    "\n",
    "# model_grid['recharge'] = model_grid.rch_eff_m_SWB_NAWQA    \n",
    "# model_grid.to_csv(os.path.join(model_ws, 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this approach maintains the overall ratio of recharge between coarse and fine sediments AND keeps much of the spatial variation \n",
    "r_SWB = model_grid.rch_eff_m_SWB_NAWQA.values.reshape(NROW, NCOL) / 365.25\n",
    "\n",
    "perDev = model_grid.PerDev.values.reshape(NROW, NCOL)\n",
    "perImp = model_grid.PerImp.values.reshape(NROW, NCOL)/100\n",
    "\n",
    "\n",
    "# r_SWB = r_SWB*(1-perDev)\n",
    "\n",
    "#use the more details surficial zones for the recharge\n",
    "SurfGeoArr = model_grid.SurfGeo.values.reshape( NROW, NCOL )\n",
    "zones1d_detailed = np.ones(( NROW, NCOL ), dtype=np.int32)\n",
    "\n",
    "#if alluvium, bedrock, artificial fill, marsh, fines, till or thick till (code 2, 3, 4, 7, 8,9, 10), then it's fine for recharge purposes, otherwise it's coarse\n",
    "zones1d_detailed[((SurfGeoArr==2) | (SurfGeoArr==3) | (SurfGeoArr==4) | (SurfGeoArr==7) | (SurfGeoArr==8) | (SurfGeoArr==9) | (SurfGeoArr==10))]=0\n",
    "\n",
    "#save the zones1d_detailed for use in calibration\n",
    "if not os.path.isdir(os.path.join(model_ws,'arrays')):\n",
    "    os.mkdir(os.path.join(model_ws,'arrays'))\n",
    "np.savetxt(os.path.join(model_ws,'arrays','zones1d_detailed.ref'), zones1d_detailed)\n",
    "np.savetxt(os.path.join(model_ws,'arrays','rech_base.ref'), r_SWB)\n",
    "np.savetxt(os.path.join(model_ws,'arrays','PerDev.ref'), perDev)\n",
    "np.savetxt(os.path.join(model_ws,'arrays','PerImp.ref'), perImp)\n",
    "\n",
    "rech_ma = np.ma.MaskedArray(r_SWB, mask=inactive)\n",
    "coarse_ma = np.ma.MaskedArray(zones1d_detailed != 0, mask=inactive)\n",
    "fine_ma = np.ma.MaskedArray(zones1d_detailed == 0, mask=inactive)\n",
    "\n",
    "total_rech = rech_ma.sum()\n",
    "Af = fine_ma.sum()\n",
    "Ac = coarse_ma.sum()\n",
    "Rf = total_rech / (rech_fact * Ac + Af)\n",
    "Rc = rech_fact * Rf\n",
    "R_meanC = np.mean(rech_ma[coarse_ma==1])\n",
    "R_meanF = np.mean(rech_ma[fine_ma==1])\n",
    "R_mean = np.mean(rech_ma)\n",
    "\n",
    "rech = np.zeros_like(r_SWB)\n",
    "rech[zones1d_detailed != 0] = r_SWB[zones1d_detailed !=0] * (Rc/R_meanC)\n",
    "rech[zones1d_detailed == 0] = r_SWB[zones1d_detailed ==0] * (Rf/R_meanF)\n",
    "\n",
    "# model_grid['recharge'] = model_grid.rch_eff_m_SWB_NAWQA*(1-model_grid.PerDev) \n",
    "model_grid['recharge'] = model_grid.rch_eff_m_SWB_NAWQA\n",
    "# model_grid.to_csv(os.path.join(model_ws, 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r_Reitz = model_grid.rch_eff_m_Reitz_2013.values.reshape(NROW, NCOL) / 365.25\n",
    "\n",
    "# rech_ma = np.ma.MaskedArray(r_Reitz, mask=inactive)\n",
    "# coarse_ma = np.ma.MaskedArray(zones1d != 0, mask=inactive)\n",
    "# fine_ma = np.ma.MaskedArray(zones1d == 0, mask=inactive)\n",
    "\n",
    "# total_rech = rech_ma.sum()\n",
    "# Af = fine_ma.sum()\n",
    "# Ac = coarse_ma.sum()\n",
    "# Rf = total_rech / (rech_fact * Ac + Af)\n",
    "# Rc = rech_fact * Rf\n",
    "\n",
    "# rech = np.zeros_like(r_Reitz)\n",
    "# rech[zones1d != 0] = Rc\n",
    "# rech[zones1d == 0] = Rf\n",
    "\n",
    "# model_grid['recharge'] = model_grid.rch_eff_m_Reitz_2013    \n",
    "# model_grid.to_csv(os.path.join(model_ws, 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Alternative recharge, to use, comment-out the above cell and uncomment this cell\n",
    "# r_Wolock = model_grid.rch_m_Wolock.values.reshape(NROW, NCOL) / 365.25\n",
    "\n",
    "# rech_ma = np.ma.MaskedArray(r_Wolock, mask=inactive)\n",
    "# coarse_ma = np.ma.MaskedArray(zones1d != 0, mask=inactive)\n",
    "# fine_ma = np.ma.MaskedArray(zones1d == 0, mask=inactive)\n",
    "\n",
    "# total_rech = rech_ma.sum()\n",
    "# Af = fine_ma.sum()\n",
    "# Ac = coarse_ma.sum()\n",
    "# Rf = total_rech / (rech_fact * Ac + Af)\n",
    "# Rc = rech_fact * Rf\n",
    "\n",
    "# rech = np.zeros_like(r_Wolock)\n",
    "# rech[zones1d != 0] = Rc\n",
    "# rech[zones1d == 0] = Rf\n",
    "\n",
    "# model_grid['recharge'] = model_grid.rch_m_Wolock    \n",
    "# model_grid.to_csv(os.path.join(model_ws, 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add the septic return flows to the recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if septic_flux.sum()>0:\n",
    "    septic_rech = septic_flux.values.reshape(NROW,NCOL)/L/L\n",
    "    np.savetxt(os.path.join(model_ws,'arrays','septic_rech.ref'), septic_rech)\n",
    "    rech = rech+septic_rech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to create and run MODFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "riv_dict[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modflow(md, mfpth, model_ws, nlay=1, top=top, strt=strt, nrow=NROW, ncol=NCOL, botm=bedrock, \n",
    "            ibound=ibound, hk=Kh1d, rech=rech, drn_dict=drn_dict, riv_dict = riv_dict, delr=L, delc=L, \n",
    "            hnoflo=hnoflo, hdry=hdry, iphdry=1, laytyp=1):\n",
    "\n",
    "    strt_dir = os.getcwd()\n",
    "    os.chdir(model_ws)\n",
    "\n",
    "    ml = fp.modflow.Modflow(modelname=md, exe_name=mfpth, version='mfnwt', \n",
    "                            external_path='arrays') \n",
    "\n",
    "    # add packages (DIS has to come before either BAS or the flow package)\n",
    "    dis = fp.modflow.ModflowDis(ml, nlay=nlay, nrow=NROW, ncol=NCOL, nper=1, delr=L, delc=L, \n",
    "                                laycbd=0, top=top, botm=botm, perlen=1.E+05, nstp=1, tsmult=1, \n",
    "                                steady=True, itmuni=4, lenuni=2, extension='dis', \n",
    "                                unitnumber=11) \n",
    "\n",
    "    bas = fp.modflow.ModflowBas(ml, ibound=ibound, strt=strt, ifrefm=True, \n",
    "                                ixsec=False, ichflg=False, stoper=None, hnoflo=hnoflo, extension='bas', \n",
    "                                unitnumber=13)\n",
    "\n",
    "    upw = fp.modflow.ModflowUpw(ml, laytyp=laytyp, layavg=0, chani=1.0, layvka=1, laywet=0, ipakcb=53, \n",
    "                                hdry=hdry, iphdry=iphdry, hk=hk, hani=1.0, vka=1.0, ss=1e-05, \n",
    "                                sy=0.15, vkcb=0.0, noparcheck=False, extension='upw', \n",
    "                                unitnumber=31)\n",
    "\n",
    "    rch = fp.modflow.ModflowRch(ml, nrchop=3, ipakcb=53, rech=rech, irch=1, \n",
    "                                extension='rch', unitnumber=19)\n",
    "\n",
    "    drn = fp.modflow.ModflowDrn(ml, ipakcb=53, stress_period_data=drn_dict, \n",
    "                                dtype=drn_dict[0].dtype,\n",
    "                                extension='drn', unitnumber=21, options=['NOPRINT', 'AUX IFACE'])\n",
    "\n",
    "    riv = fp.modflow.ModflowRiv(ml, ipakcb=53, stress_period_data=riv_dict, \n",
    "                                dtype=riv_dict[0].dtype,\n",
    "                                extension='riv', unitnumber=18, options=['NOPRINT', 'AUX IFACE'])\n",
    "\n",
    "    if GHB:\n",
    "        ghb = fp.modflow.ModflowGhb(ml, ipakcb=53, stress_period_data=ghb_dict, \n",
    "                                dtype=ghb_dict[0].dtype,\n",
    "                                extension='ghb', unitnumber=23, options=['NOPRINT', 'AUX IFACE'])\n",
    "    if GHB_sea:\n",
    "        ghb = fp.modflow.ModflowGhb(ml, ipakcb=53, stress_period_data=ghb_sea_dict, \n",
    "                                dtype=ghb_sea_dict[0].dtype,\n",
    "                                extension='ghb', unitnumber=23, options=['NOPRINT', 'AUX IFACE'])\n",
    "    if septic:\n",
    "        thisWell = deepcopy(well_dict[0])\n",
    "        #adjust the layers for the 1 layer model\n",
    "        thisWell['k'][thisWell['k']>nlay]=nlay-1\n",
    "        #only keep the rows with non-zero flow\n",
    "        thisWell = thisWell[thisWell['Q']!=0]\n",
    "\n",
    "        #aggregate wells that are in the same cells\n",
    "        #convert array to df\n",
    "        thisWell_df = pd.DataFrame(thisWell)\n",
    "        thisWell_df = thisWell_df.groupby(['k','i','j']).sum().reset_index()\n",
    "        thisWell = thisWell_df.to_records(index=False)\n",
    "        well = fp.modflow.ModflowWel(ml, ipakcb=53,stress_period_data = {0:thisWell}, dtype=well_dict[0].dtype,extension='wel', options=[\"NOPRINT\"])\n",
    "        \n",
    "\n",
    "    oc = fp.modflow.ModflowOc(ml, ihedfm=0, iddnfm=0, chedfm=None, cddnfm=None, cboufm=None, \n",
    "                              compact=True, stress_period_data={(0, 0): ['save head', 'save budget']}, \n",
    "                              extension=['oc', 'hds', 'ddn', 'cbc'], unitnumber=[14, 51, 52, 53])\n",
    "\n",
    "#     nwt = fp.modflow.ModflowNwt(ml, headtol=0.0001, fluxtol=500, maxiterout=1000, \n",
    "#                                 thickfact=1e-05, linmeth=2, iprnwt=1, ibotav=0, options='COMPLEX')\n",
    "\n",
    "# below was used prior to March 2018\n",
    "#     nwt = fp.modflow.ModflowNwt(ml, headtol=0.0001, fluxtol=500, maxiterout=100, thickfact=1e-05, \n",
    "#                                 linmeth=2, iprnwt=1, ibotav=1, options='SPECIFIED', dbdtheta =0.80, \n",
    "#                                 dbdkappa = 0.00001, dbdgamma = 0.0, momfact =  0.10, backflag = 1, \n",
    "#                                 maxbackiter=30, backtol=1.05, backreduce=0.4, iacl=2, norder=1, \n",
    "#                                 level=3, north=7, iredsys=1, rrctols=0.0,idroptol=1, epsrn=1.0E-3,\n",
    "#                                 hclosexmd= 1.0e-4, mxiterxmd=200)\n",
    "\n",
    "#below reflects changes to make solving easier, March 2018\n",
    "    thisIterMax = 1000\n",
    "#     if md in ['CoastalCT500','CoastalCT250']:\n",
    "#         thisIterMax = 2000\n",
    "    nwt = fp.modflow.ModflowNwt(ml, headtol=0.0001, fluxtol=500, maxiterout=thisIterMax, thickfact=1e-05, \n",
    "                                linmeth=2, iprnwt=1, ibotav=1, options='SPECIFIED', dbdtheta =0.10, \n",
    "                                dbdkappa = 0.00001, dbdgamma = 0.01, momfact =  0.10, backflag = 1, \n",
    "                                maxbackiter=10, backtol=1.05, backreduce=0.4, iacl=2, norder=1, \n",
    "                                level=3, north=7, iredsys=1, rrctols=0.0,idroptol=1, epsrn=1.0E-3,\n",
    "                                hclosexmd= 1.0e-4, mxiterxmd=200)\n",
    "\n",
    "#     ml.write_input()\n",
    "    \n",
    "    if not \"RIV\" in scenarioLabel:\n",
    "        ml.remove_package('RIV')\n",
    "\n",
    "    ml.write_input()\n",
    "    success, output = ml.run_model(silent=False)\n",
    "    os.chdir(strt_dir)\n",
    "    if success:\n",
    "        print(\"    Your {:0d} layer model ran successfully\".format(nlay))\n",
    "    else:\n",
    "        print(\"    Your {:0d} layer model didn't work\".format(nlay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1-layer MODFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function to run MODFLOW for 1 layer to getting approximate top-of-aquifer elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modflow(md, mfpth, model_ws, nlay=1, top=top, strt=strt, nrow=NROW, ncol=NCOL, botm=bot, ibound=ibound, \n",
    "        hk=Kh1d, rech=rech, drn_dict=drn_dict, delr=L, delc=L, hnoflo=hnoflo, hdry=hdry, iphdry=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the head file and calculate new layer top (wt) and bottom (bot) elevations based on the estimated\n",
    "water table (wt) being the top of the top layer. Divide the surficial layer into NLAY equally thick layers between wt and the bedrock surface elevation (as computed using minimum surficial thickness). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdobj = fp.utils.HeadFile(head_file_pth)\n",
    "heads1 = hdobj.get_data(kstpkper=(0, 0))\n",
    "heads1[heads1 == hnoflo] = np.nan\n",
    "heads1[heads1 <= hdry] = np.nan\n",
    "heads1 = heads1[0, :, :]\n",
    "hdobj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(top[370:375,672:677])\n",
    "# print(rech[370:375,672:677])\n",
    "# print(heads1[370:375,672:677])\n",
    "# print(frf[0,370:375,672:677])\n",
    "# print(fff[0,370:375,672:677])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constantHead = cbb.get_data(text='CONSTANT HEAD')[0]\n",
    "# recharge = cbb.get_data(text='RECHARGE')[0][0]\n",
    "# wells = cbb.get_data(text='WELLS')[0]\n",
    "# drains = cbb.get_data(text='DRAINS')[0]\n",
    "# headDepBounds = cbb.get_data(text='HEAD DEP BOUNDS')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thisRow = 373\n",
    "# thisCol = 675\n",
    "# ml = fp.modflow.Modflow.load('%s.nam'%(md),model_ws=model_ws)\n",
    "# hdobj = fp.utils.HeadFile(head_file_pth)\n",
    "# headsplot = hdobj.get_data(kstpkper=(0, 0))\n",
    "# headsplot[headsplot == hnoflo] = np.nan\n",
    "# headsplot[headsplot <= hdry] = np.nan\n",
    "# fname = os.path.join(model_ws, '%s.cbc'%(md))\n",
    "# cbb = fp.utils.CellBudgetFile(fname)\n",
    "# frf = cbb.get_data(text='FLOW RIGHT FACE')[0]\n",
    "# fff = cbb.get_data(text='FLOW FRONT FACE')[0]\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "# ax.set_title('plot_array()')\n",
    "# modelmap = fp.plot.ModelMap(model=ml, extent = ((thisCol-1)*L,(thisCol+2)*L,(NROW-thisRow-1)*L,(NROW-thisRow+2)*L))\n",
    "# quadmesh = modelmap.plot_ibound()\n",
    "# quadmesh = modelmap.plot_array(top, masked_values=[999.], alpha=0.5)\n",
    "# # quadmesh = modelmap.plot_bc('DRN', color='purple')\n",
    "# # quadmesh = modelmap.plot_bc('WEL', color='navy')\n",
    "# # quadmesh = modelmap.plot_bc('RIV', color='yellow')\n",
    "# quiver = modelmap.plot_discharge(frf, fff, head=headsplot)\n",
    "# linecollection = modelmap.plot_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create layering using the scenario in gen_mod_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new model with (possibly) multiple layers. If there are dry cells in the 1 layer model, they are converted to NaN (not a number). The minimum function in the first line returns NaN if the element of either input arrays is NaN.  In that case, replace NaN in modeltop with the top elevation. The process is similar to the 1 layer case. Thickness is estimated based on modeltop and bedrock and is constrained to be at least min_thk (set in gen_mod_dict.py). This thickness is divided into num_surf_layers number of layers. The cumulative thickness of these layers is the distance from the top of the model to the bottom of the layers. This 3D array of distances (the same for each layer) is subtracted from modeltop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modflow adjusts the pumping from wells to prevent dewatering. In adjusting the model top to the water table elevation, we want those cells to reflect NaN (so the new model top is the current land surface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the actual pumping rates\n",
    "fname = os.path.join(model_ws, '%s.cbc'%(md))\n",
    "cbb = fp.utils.CellBudgetFile(fname)\n",
    "wellPumpDF = pd.DataFrame(cbb.get_data(text='WELLS')[0])\n",
    "wellPumpDF.columns=['node_num','well_q']\n",
    "#add 1 to the node to match the numbering in model_gri\n",
    "wellPumpDF['node_num'] = wellPumpDF['node_num']-1\n",
    "wellPumpDF.set_index('node_num', inplace=True)\n",
    "#get the specified pumping and merge in the actual pumping\n",
    "specifiedPump = model_grid[['row','col']]\n",
    "\n",
    "#get the actual pumping and aggregate by row / col\n",
    "pumpSpecs = pd.DataFrame(well_dict[0])\n",
    "pumpSpecs.drop('k', axis=1,inplace=True)\n",
    "pumpSpecs = pumpSpecs.groupby(['i','j']).sum().reset_index()\n",
    "\n",
    "specifiedPump = specifiedPump.merge(pumpSpecs,\"left\",left_on=['row','col'],right_on=['i','j'])\n",
    "specifiedPump = specifiedPump.merge(wellPumpDF,\"left\", left_index=True, right_index=True)\n",
    "#switch 0 in the specified pumping rate to Nan\n",
    "specifiedPump.loc[specifiedPump.Q==0,'Q']=np.nan\n",
    "index = np.invert(np.isclose(specifiedPump.Q, specifiedPump.well_q,atol=0.1, rtol=0,equal_nan=True))\n",
    "reducedPumping = index.reshape(NROW,NCOL)\n",
    "\n",
    "#change the head in cells with reducing pumping to dry\n",
    "heads1[reducedPumping]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modeltop = np.minimum(heads1, top)\n",
    "nan = np.isnan(heads1)\n",
    "modeltop[nan] = top[nan]\n",
    "\n",
    "#don't use the fake top for SFRtest models\n",
    "if \"_SFRtest\" in scenarioLabel:\n",
    "    modeltop = top\n",
    "\n",
    "# stg = model_grid.drain_elev.values.reshape(NROW, NCOL)\n",
    "# stg[stg==-100000]=-1.E+30\n",
    "# stg[np.isnan(stg)]=-1.E+30\n",
    "# modeltop = np.maximum(modeltop, stg)\n",
    "\n",
    "thk = modeltop - bedrock\n",
    "thk[thk < min_thk] = min_thk\n",
    "\n",
    "\n",
    "NLAY = num_surf_layers\n",
    "lay_extrude = np.ones((NLAY, NROW, NCOL))\n",
    "lay_thk = lay_extrude * thk / NLAY\n",
    "bot = modeltop - np.cumsum(lay_thk, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the estimated water table as the new top-of-aquifer elevations sometimes leads to the situation, in usually a very small number of cells, that the drain elevation is below the bottom of the cell.  The following procedure resets the bottom elevation to one meter below the drain elevation if that is the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stg = model_grid.drain_elev.values.reshape(NROW, NCOL)\n",
    "stg[stg<-100000]=1.E+30\n",
    "stg[np.isnan(stg)]=1.E+30\n",
    "tmpdrn = (lay_extrude * stg).ravel()\n",
    "tmpbot = bot.ravel()\n",
    "index = np.less(tmpdrn, tmpbot)\n",
    "tmpbot[index] = tmpdrn[index] - 1.0\n",
    "bot = tmpbot.reshape(NLAY, NROW, NCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ghb = deepcopy(model_grid.fresh_head.values.reshape(NROW, NCOL))\n",
    "ghb_sea = model_grid.ghb_sea.values.reshape(NROW,NCOL)\n",
    "ghb[ghb_sea==0]=1.E+30\n",
    "tmpdrn = (lay_extrude * ghb).ravel()\n",
    "tmpbot = bot.ravel()\n",
    "index = np.less(tmpdrn, tmpbot)\n",
    "tmpbot[index] = tmpdrn[index] - 1.0\n",
    "bot = tmpbot.reshape(NLAY, NROW, NCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enforce layer thicknesses due to changes in elevations from drains and ghb\n",
    "for i in range((bot.shape[0]-1)):\n",
    "    bot[(i+1),(bot[i]-bot[i+1])<(min_thk/num_surf_layers)]=bot[(i),(bot[i]-bot[i+1])<(min_thk/num_surf_layers)]-min_thk/num_surf_layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If add_bedrock = True in gen_mod_dict.py, add a layer to the bottom and increment NLAY by 1.\n",
    "* Assign the new bottom-most layer an elevation equal to the elevation of the bottom of the lowest surficial layer minus bedrock_thk, which is specified in rock_riv_dict (in gen_mod_dict.py).\n",
    "* Concatenate the new bottom-of-bedrock-layer to the bottom of the surficial bottom array.\n",
    "* Compute the vertical midpoint of each cell. Make an array (bedrock_index) that is True if the bedrock surface is higher than the midpoint and False if it is not.\n",
    "* lay_extrude replaces the old lay_extrude to account for the new bedrock layer. It is not used in this cell, but is used later to extrude other arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kauffman_CTquat_thk = model_grid.kauffman_CTquat_thk.values.reshape(NROW, NCOL)\n",
    "tmp = top - kauffman_CTquat_thk\n",
    "bedrock_4_K = bedrock.copy()\n",
    "bedrock_4_K[bedrock > top] = tmp[bedrock > top]\n",
    "\n",
    "if add_bedrock:\n",
    "    NLAY = num_surf_layers + 1\n",
    "    lay_extrude = np.ones((NLAY, NROW, NCOL))\n",
    "    bed_bot = bot[-1:,:,:] - bedrock_thk\n",
    "    bot = np.concatenate((bot, bed_bot), axis=0)\n",
    "\n",
    "    mids = bot + thk / NLAY / 2\n",
    "    bedrock_index = mids < bedrock_4_K\n",
    "    bedrock_index[-1:,:,:] = True\n",
    "\n",
    "elif not add_bedrock:\n",
    "    print('    no bedrock')\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    print('    add_bedrock variable needs to True or False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrude all arrays to NLAY number of layers. Create a top-of-aquifer elevation (fake_top) that is higher (20% in this case) than the simulated 1-layer water table because in doing this approximation, some stream elevations end up higher than top_of_aquifer and thus do not operate as drains. The fake_top shouldn't affect model computations if it is set high enough because the model uses convertible (confined or unconfined) layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_top = (modeltop+np.abs(modeltop)*0.2).astype(np.float32)\n",
    "ibound = (lay_extrude * ibound).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the mapping from zone number to K to create the Kh3d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#limit the fake_top to the height of the land surface (no higher)\n",
    "fake_top = np.minimum(fake_top, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#actually we want the model top at the sea floor for the marine boundary\n",
    "# #ensure the fake_top is above the marine boundaries\n",
    "# fresh_head =  model_grid.fresh_head.values.reshape(NROW, NCOL)\n",
    "# ghb_sea = model_grid.ghb_sea.values.reshape(NROW, NCOL)\n",
    "# #use a really large number for the fresh head where there is no ghb_sea so the minimum is always the other\n",
    "# fresh_head[ghb_sea==0]=-100000\n",
    "# fake_top = np.maximum(fake_top,fresh_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ensure the fake_top is above river boundaries\n",
    "stage =  model_grid.drain_elev.values.reshape(NROW, NCOL)\n",
    "\n",
    "#use a really small number for the stage where there is no river so the maximum is always the other\n",
    "stage[np.isnan(stage)]=-100000\n",
    "stage[stage>1000000]=-100000\n",
    "fake_top = np.maximum(fake_top,stage)\n",
    "\n",
    "#and ensure the fake_top is above \"inland\" coastal waters\n",
    "fresh_head = deepcopy(model_grid.fresh_head.values.reshape(NROW,NCOL))\n",
    "fresh_head[fresh_head<=0]=np.nan\n",
    "fresh_head[fresh_head>1000000]=-100000\n",
    "fresh_head[np.isnan(fresh_head)]=-100000\n",
    "fake_top = np.maximum(fake_top,fresh_head)\n",
    "\n",
    "strt = (lay_extrude * modeltop * 1.05).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zones3d = np.zeros(( NLAY, NROW, NCOL ), dtype=np.int32)\n",
    "\n",
    "gess = model_grid.gess_poly.values.reshape(NROW, NCOL)\n",
    "gess3d = (lay_extrude * gess).astype(np.int32)\n",
    "\n",
    "zones3d[gess3d == 0] = 0\n",
    "zones3d[gess3d == 1] = 1\n",
    "\n",
    "if add_bedrock:\n",
    "    zones3d[bedrock_index] = 3\n",
    "\n",
    "la = model_grid.lake.values.reshape(NROW, NCOL)\n",
    "zones3d[0, la == 1] = 2\n",
    "\n",
    "Kh3d = np.zeros(( NLAY, NROW, NCOL ), dtype=np.float32)\n",
    "\n",
    "for key, val in zone_dict.items():\n",
    "    Kh3d[zones3d == key] = K_dict[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MODFLOW again using the new layer definitions.  The difference from the first run is that the top-of-aquifer elevation is the 1-layer water table rather than land surface, and of course, the number of surficial layers and/or the presence of a bedrock layer is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(fake_top[113:116,635:638])\n",
    "print(bot[:,113:116,635:638])\n",
    "print(stg[113:116,635:638])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if bedConfined:\n",
    "    laytypeLst = [1]*(NLAY-1)\n",
    "    laytypeLst.append(0)\n",
    "else:\n",
    "    laytypeLst=1\n",
    "modflow(md, mfpth, model_ws, nlay=NLAY, top=fake_top, strt=strt, nrow=NROW, ncol=NCOL, \n",
    "        botm=bot, ibound=ibound, hk=Kh3d, rech=rech, drn_dict=drn_dict, delr=L, \n",
    "        delc=L, hnoflo=hnoflo, hdry=hdry, iphdry=1, laytyp=laytypeLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid.loc[(model_grid.row==601)&(model_grid.col==34)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the new head array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdobj = fp.utils.HeadFile(head_file_pth)\n",
    "heads = hdobj.get_data()\n",
    "hdobj = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a 2D array of the heads in the highest active cells and call it the water_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heads[heads == hnoflo] = np.nan\n",
    "heads[heads <= hdry] = np.nan\n",
    "hin = np.argmax(np.isfinite(heads), axis=0)\n",
    "row, col = np.indices((hin.shape))\n",
    "water_table = heads[hin, row, col]\n",
    "\n",
    "water_table_ma = np.ma.MaskedArray(water_table, inactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the head array to a geotiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = water_table_ma\n",
    "\n",
    "src_pth = os.path.join(geo_ws, 'ibound.tif')\n",
    "src = gdal.Open(src_pth)\n",
    "\n",
    "dst_pth = os.path.join(model_ws, 'pre-heads.tif')\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dst = driver.CreateCopy(dst_pth, src, 0)\n",
    "\n",
    "band = dst.GetRasterBand(1)\n",
    "band.WriteArray(data)\n",
    "band.SetNoDataValue(np.nan)\n",
    "\n",
    "dst = None\n",
    "src = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the heads and K from the upper-most layer to model_grid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_grid['pre_cal_heads'] = water_table_ma.ravel()\n",
    "model_grid['pre_cal_K'] = Kh3d[0,:,:].ravel()\n",
    "\n",
    "if add_bedrock:\n",
    "    model_grid['thk'] = model_grid.top - bot[-1,:,:].ravel() + bedrock_thk\n",
    "else:\n",
    "    model_grid['thk'] = model_grid.top - bot[-1,:,:].ravel()\n",
    "\n",
    "model_grid['thkR'] = model_grid.thk / model_grid.recharge\n",
    "    \n",
    "model_grid.to_csv(os.path.join(model_ws, 'model_grid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save zone array for use in calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zone_file = os.path.join(model_ws, 'zone_array.npz')\n",
    "np.savez(zone_file, zone=zones3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a second zone array with more details surficial and bedrock geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zones3d_detailed = deepcopy(zones3d)\n",
    "surf_detailed = model_grid.SurfGeo.values.reshape(NROW, NCOL)\n",
    "bedrock_geo = model_grid.BedLithSimp.values.reshape(NROW,NCOL)\n",
    "zones3d_bedrock = deepcopy(zones3d_detailed)\n",
    "zones3d_bedrock[zones3d_bedrock!=3]=0\n",
    "zones3d_bedrock[zones3d_bedrock!=0]=1\n",
    "\n",
    "zones3d_surf = deepcopy(zones3d_detailed)\n",
    "zones3d_surf[zones3d_surf!=3]=1\n",
    "zones3d_surf[zones3d_surf==3]=0\n",
    "\n",
    "\n",
    "zones3d_surf = zones3d_surf * surf_detailed\n",
    "zones3d_bedrock = zones3d_bedrock * bedrock_geo\n",
    "\n",
    "#switch the \"bedrock\" zone in the surficial layers to the appropriate type\n",
    "for i in range(NLAY):\n",
    "    zones3d_surf[i][zones3d_surf[i]==4] = zones3d_bedrock[3][zones3d_surf[i]==4] \n",
    "\n",
    "#switch the \"unconsolidated\" zone in the bedrock layers to the appropriate type\n",
    "# for i in range(NLAY):\n",
    "#     zones3d_bedrock[i] [zones3d_bedrock[i]==2000] = zones3d_surf[0][zones3d_bedrock[i]==2000]\n",
    "\n",
    "zones3d_detailed = zones3d_surf + zones3d_bedrock\n",
    "\n",
    "#add in the lakes\n",
    "la = model_grid.lake.values.reshape(NROW, NCOL)\n",
    "zones3d_detailed [0][la == 1] = 2300\n",
    "\n",
    "zone_file = os.path.join(model_ws, 'zone_array_detailed.npz')\n",
    "np.savez(zone_file, zone=zones3d_detailed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a cross-section to see what the layers look like.  Change row_to_plot to see other rows.  Columns could be easily added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_error(top, head, obs_type):\n",
    "    # an offset of 1 is used to eliminate counting heads that\n",
    "    # are within 1 m of their target as errors.\n",
    "    # count topo and hydro errors\n",
    "    t = top < (head - err_tol)\n",
    "    h = top > (head + err_tol)\n",
    "\n",
    "    tmp_df = pd.DataFrame({'head':head, 'ot':obs_type, 't':t, 'h':h})\n",
    "\n",
    "    tmp = tmp_df.groupby('ot').sum()\n",
    "    h_e_ = tmp.loc['hydro', 'h']\n",
    "    t_e_ = tmp.loc['topo', 't']\n",
    "    result = np.array([h_e_, t_e_])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hydro, topo = calc_error(model_grid.top, water_table.ravel(), model_grid.obs_type)\n",
    "num_hydro = model_grid.obs_type.value_counts()['hydro']\n",
    "num_topo = model_grid.obs_type.value_counts()['topo']\n",
    "num_cells = num_hydro + num_topo\n",
    "hydro = hydro / num_hydro\n",
    "topo = topo / num_topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ma2(data2D):\n",
    "    return np.ma.MaskedArray(data2D, mask=inactive)\n",
    "\n",
    "def ma3(data3D):\n",
    "    return np.ma.MaskedArray(data3D, mask=(ibound == 0))\n",
    "\n",
    "row_to_plot = NROW / 2\n",
    "xplot = np.linspace( L / 2, NCOL * L - L / 2, NCOL)\n",
    "\n",
    "mKh = ma3(Kh3d)\n",
    "mtop = ma2(top)\n",
    "mbed = ma2(bedrock)\n",
    "mbot = ma3(bot)\n",
    "\n",
    "colors = ['green', 'red', 'gray']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "ax1.plot(xplot, mtop[row_to_plot, ], label='land surface', color='black', lw=0.5)\n",
    "ax1.plot(xplot, water_table_ma[row_to_plot, ], label='water table', color='blue', lw=1.)\n",
    "ax1.fill_between(xplot, mtop[row_to_plot, ], mbot[0, row_to_plot, :], alpha=0.25, \n",
    "                 color='blue', label='layer 1', lw=0.75)\n",
    "for lay in range(NLAY-1):\n",
    "    label = 'layer {}'.format(lay+2)\n",
    "    ax1.fill_between(xplot, mbot[lay, row_to_plot, :], mbot[lay+1, row_to_plot, :], label=label, \n",
    "                    color=colors[lay], alpha=0.250, lw=0.75)\n",
    "ax1.plot(xplot, mbed[row_to_plot, :], label='bedrock (Soller)', color='red', linestyle='dotted', lw=1.5)\n",
    "ax1.plot(xplot, mbot[-1, row_to_plot, :], color='black', linestyle='solid', lw=0.5)\n",
    "ax1.legend(loc=0, frameon=False, fontsize=10, ncol=3)#, bbox_to_anchor=(1.0, 0.5))\n",
    "ax1.set_ylabel('Altitude, in meters')\n",
    "ax1.set_xticklabels('')\n",
    "ax1.set_title('Default section along row {}, {} model, weight {:0.1f}\\nK fine = {:0.1f}  K coarse = {:0.1f}\\\n",
    " K bedrock = {:0.1f}\\nFraction dry drains {:0.2f} Fraction flooded cells {:0.2f}'.format(row_to_plot, \\\n",
    " md, 1,  K_dict['K_fine'], K_dict['K_coarse'], K_dict['K_bedrock'], hydro, topo))\n",
    "\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax2.fill_between(xplot, 0, mKh[0, row_to_plot, :], alpha=0.25, color='blue', \n",
    "                 label='layer 1', lw=0.75, step='mid')\n",
    "ax2.set_xlabel('Distance in meters')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel('Hydraulic conductivity\\n in layer 1, in meters / day')\n",
    "\n",
    "line = '{}_{}_xs.png'.format(md, scenario_dir)\n",
    "fig_name = os.path.join(model_ws, line)\n",
    "plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = top < (water_table - err_tol)\n",
    "h = top > (water_table + err_tol)\n",
    "\n",
    "mt = np.ma.MaskedArray(t.reshape(NROW, NCOL), model_grid.obs_type != 'topo')\n",
    "mh = np.ma.MaskedArray(h.reshape(NROW, NCOL), model_grid.obs_type != 'hydro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "cmap = colors.ListedColormap(['0.50', 'red'])\n",
    "cmap2 = colors.ListedColormap(['blue'])\n",
    "\n",
    "back = np.ma.MaskedArray(ibound[0,:,:], ibound[0,:,:] == 0)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(back, cmap=cmap2, alpha=0.2)\n",
    "im0 = ax[0].imshow(mh, cmap=cmap, interpolation='None')\n",
    "ax[0].axhline(row_to_plot)\n",
    "# fig.colorbar(im0, ax=ax[0])\n",
    "ax[1].imshow(back, cmap=cmap2, alpha=0.2)\n",
    "im1 = ax[1].imshow(mt, cmap=cmap, interpolation='None')\n",
    "ax[1].axhline(row_to_plot)\n",
    "# fig.colorbar(im1, ax=ax[1])\n",
    "fig.suptitle('Default model errors (in red) along row {}, {} model, weight {:0.1f}\\nK fine = {:0.1f}  K coarse = {:0.1f}\\\n",
    " K bedrock = {:0.1f}\\nFraction dry drains {:0.2f} Fraction flooded cells {:0.2f}'.format(row_to_plot, \\\n",
    " md, 1.0, K_dict['K_fine'], K_dict['K_coarse'], K_dict['K_bedrock'], hydro, topo))\n",
    "\n",
    "# fig.subplots_adjust(left=None, bottom=None, right=None, top=None,\n",
    "#                       wspace=None, hspace=None)\n",
    "\n",
    "fig.set_size_inches(6, 6)\n",
    "\n",
    "# line = '{}_{}_error_map_cal.png'.format(md, scenario_dir)\n",
    "line = '{}_{}_error_map.png'.format(md, scenario_dir)   #csc\n",
    "fig_name = os.path.join(model_ws, line)\n",
    "plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml = fp.modflow.Modflow.load('%s.nam'%(md),model_ws=model_ws)\n",
    "fname = os.path.join(model_ws, '%s.cbc'%(md))\n",
    "cbb = fp.utils.CellBudgetFile(fname)\n",
    "frf = cbb.get_data(text='FLOW RIGHT FACE')[0]\n",
    "fff = cbb.get_data(text='FLOW FRONT FACE')[0]\n",
    "flf = cbb.get_data(text='FLOW LOWER FACE')[0]\n",
    "\n",
    "hdobj = fp.utils.HeadFile(head_file_pth)\n",
    "heads1 = hdobj.get_data(kstpkper=(0, 0))\n",
    "heads1[heads1 == hnoflo] = np.nan\n",
    "heads1[heads1 <= hdry] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "thisCol = 616\n",
    "startRow = 254\n",
    "endRow = 258\n",
    "ymax = np.nanmax(top[startRow:(endRow+1),thisCol])+0.1*np.abs(np.nanmax(top[startRow:(endRow+1),thisCol]))\n",
    "ymin = np.nanmin(bot[-1,startRow:(endRow+1),thisCol])-0.1*np.abs(np.nanmin(bot[-1,startRow:(endRow+1),thisCol]))\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_title('plot_array() and plot_discharge()')\n",
    "modelxsect = fp.plot.ModelCrossSection(model=ml, ax=ax, line={'Column': thisCol}, extent=( startRow*L,(endRow+1)*L,ymin,ymax))\n",
    "csa = modelxsect.plot_array(heads1, masked_values=[999.], head=heads1, alpha=0.5)\n",
    "linecollection = modelxsect.plot_grid()\n",
    "quiver = modelxsect.plot_discharge(frf, fff, flf=flf, head=heads1, \n",
    "                                   hstep=2, normalize=True, color='green', \n",
    "                                   scale=30, headwidth=3, headlength=3, headaxislength=3,\n",
    "                                   zorder=10)\n",
    "# patches = modelxsect.plot_ibound(head=heads1)\n",
    "# patches = modelxsect.plot_bc('WEL') #red\n",
    "try:\n",
    "    patches = modelxsect.plot_bc('RIV') #green\n",
    "except:\n",
    "        pass\n",
    "patches = modelxsect.plot_bc('DRN') #yellow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "thisCol = 420\n",
    "startRow = 258\n",
    "endRow = 260\n",
    "ymax = np.nanmax(top[startRow:(endRow+1),thisCol])+0.1*np.abs(np.nanmax(top[startRow:(endRow+1),thisCol]))\n",
    "ymin = np.nanmin(bot[-1,startRow:(endRow+1),thisCol])-0.1*np.abs(np.nanmin(bot[-1,startRow:(endRow+1),thisCol]))\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_title('plot_array() and plot_discharge()')\n",
    "modelxsect = fp.plot.ModelCrossSection(model=ml, ax=ax, line={'Column': thisCol}, extent=( startRow*L,(endRow+1)*L,ymin,ymax))\n",
    "csa = modelxsect.plot_array(Kh3d, masked_values=[999.], head=heads1, alpha=0.5)\n",
    "linecollection = modelxsect.plot_grid()\n",
    "quiver = modelxsect.plot_discharge(frf, fff, flf=flf, head=heads1, \n",
    "                                   hstep=2, normalize=True, color='green', \n",
    "                                   scale=30, headwidth=3, headlength=3, headaxislength=3,\n",
    "                                   zorder=10)\n",
    "# patches = modelxsect.plot_ibound(head=heads1)\n",
    "# patches = modelxsect.plot_bc('WEL') #red\n",
    "try:\n",
    "    patches = modelxsect.plot_bc('RIV') #green\n",
    "except:\n",
    "        pass\n",
    "patches = modelxsect.plot_bc('DRN') #yellow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "thisRow = 259\n",
    "startCol = 419\n",
    "endCol = 421\n",
    "ymax = np.nanmax(top[thisRow,startCol:(endCol+1)])+0.1*np.abs(np.nanmax(top[thisRow,startCol:(endCol+1)]))\n",
    "ymin = np.nanmin(bot[-1,thisRow,startCol:(endCol+1)])-0.1*np.abs(np.nanmin(bot[-1,thisRow,startCol:(endCol+1)]))\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_title('plot_array() and plot_discharge()')\n",
    "modelxsect = fp.plot.ModelCrossSection(model=ml, ax=ax, line={'Row': thisRow}, extent=( startCol*L,(endCol+1)*L,ymin,ymax))\n",
    "csa = modelxsect.plot_array(heads1, masked_values=[999.], head=heads1, alpha=0.5)\n",
    "linecollection = modelxsect.plot_grid()\n",
    "quiver = modelxsect.plot_discharge(frf, fff, flf=flf, head=heads1, \n",
    "                                   hstep=2, normalize=True, color='green', \n",
    "                                   scale=30, headwidth=3, headlength=3, headaxislength=3,\n",
    "                                   zorder=10)\n",
    "patches = modelxsect.plot_ibound(head=heads1)\n",
    "patches = modelxsect.plot_bc('WEL') #red\n",
    "try:\n",
    "    patches = modelxsect.plot_bc('RIV') #green\n",
    "except:\n",
    "    pass\n",
    "patches = modelxsect.plot_bc('DRN') #yellow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thisRow = 259\n",
    "thisCol = 420\n",
    "ml = fp.modflow.Modflow.load('%s.nam'%(md),model_ws=model_ws)\n",
    "hdobj = fp.utils.HeadFile(head_file_pth)\n",
    "headsplot = hdobj.get_data(kstpkper=(0, 0))\n",
    "headsplot[headsplot == hnoflo] = np.nan\n",
    "headsplot[headsplot <= hdry] = np.nan\n",
    "fname = os.path.join(model_ws, '%s.cbc'%(md))\n",
    "cbb = fp.utils.CellBudgetFile(fname)\n",
    "frf = cbb.get_data(text='FLOW RIGHT FACE')[0]\n",
    "fff = cbb.get_data(text='FLOW FRONT FACE')[0]\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "ax.set_title('plot_array()')\n",
    "modelmap = fp.plot.ModelMap(model=ml, extent = ((thisCol-1)*L,(thisCol+2)*L,(NROW - thisRow+1)*L,(NROW - thisRow-2)*L), layer = 0)\n",
    "quadmesh = modelmap.plot_ibound()\n",
    "quadmesh = modelmap.plot_array(headsplot, masked_values=[999.], alpha=0.5)\n",
    "# quadmesh = modelmap.plot_bc('DRN', color='purple')\n",
    "quadmesh = modelmap.plot_bc('WEL', color='navy')\n",
    "# quadmesh = modelmap.plot_bc('RIV', color='yellow')\n",
    "quiver = modelmap.plot_discharge(frf, fff,flf=flf, head=headsplot)\n",
    "linecollection = modelmap.plot_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Drn = cbb.get_data(text=b' DRAINS')[0]\n",
    "Drn_DF = pd.DataFrame(Drn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rivData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "riv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(model_grid.population[(model_grid.ibound==1)&(model_grid.population!=0)],[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml.output_binflag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
